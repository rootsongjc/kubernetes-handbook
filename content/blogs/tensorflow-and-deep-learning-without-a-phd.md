+++
date = "2017-04-05T21:52:01+08:00"
title = "TensorFlowæ·±åº¦å­¦ä¹ æ‰‹å†™æ•°å­—è¯†åˆ«åˆä½“éªŒ"
draft = false
Tags = ["tensorflow","deep learning"]

+++

![ç¦¾é›€](http://olz1di9xf.bkt.clouddn.com/201703085.jpg)

*ï¼ˆé¢˜å›¾ï¼šç¦¾é›€ @åŒ—äº¬åŠ¨ç‰©å›­ Apr 3,2017ï¼‰*

## å‰è¨€

TensorFlowå­¦ä¹ æ›²çº¿æ˜¯é™¡å³­çš„ï¼Œä¸æ˜¯æ‰€æœ‰çš„ITä»ä¸šäººå‘˜éƒ½å¾ˆå®¹æ˜“å‚ä¸çš„ï¼Œä½ éœ€è¦æœ‰ä¸€å®šçš„æ•°å­¦ä¸“ä¸šçŸ¥è¯†ï¼Œå¯¹äºå¯¹æ·±åº¦å­¦ä¹ æ²¡æœ‰ç»éªŒçš„ç¨‹åºå‘˜ï¼Œè¦æƒ³äº†è§£è¿™é—¨æŠ€æœ¯ï¼Œæœ€å¿«æ·çš„é€”å¾„æ˜¯å…ˆè¿è¡Œä¸€ä¸ªç¤ºä¾‹ï¼Œæˆ‘ä»¬è®¤è¯†äº‹ç‰©éƒ½æ˜¯å…ˆä»æ„Ÿæ€§ã€åˆ°ç†æ€§çš„æ€è¾¨è¿‡ç¨‹ã€‚

ä¸‹é¢æˆ‘ä»¬æ¥è·Ÿéš**Martin Gorner**çš„[TensorFlow and Deep Learing Without a PhD](https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/#0)æ¥ç¼–å†™æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªTensorFlowç¨‹åºâ€”â€”æ‰‹å†™æ•°å­—è¯†åˆ«ï¼Œè¿™ç¯‡æ–‡ç« çš„ä¸­æ–‡ç‰ˆ[æ²¡æœ‰åšå£«å­¦ä½å¦‚ä½•ç©è½¬TensorFlowå’Œæ·±åº¦å­¦ä¹ ](http://www.jiqizhixin.com/article/2458)äº2017å¹´3æœˆ13æ—¥å‘è¡¨åœ¨å‘è¡¨åœ¨[æœºå™¨ä¹‹å¿ƒ](www.jiqizhixin.com)ä¸Šã€‚è¿™ç¯‡æ–‡ç« ä¹Ÿæ˜¯æ ¹æ®3æœˆ8æ—¥-10æ—¥çš„**Google Cloud NEXT'17**å¤§ä¼šä¸ŠMartin Gorneråšçš„è®²è§£æ•´ç†è€Œæˆçš„ï¼Œ[æ•™ç¨‹ | æ²¡æœ‰åšå£«å­¦ä½ï¼Œç…§æ ·ç©è½¬TensorFlowæ·±åº¦å­¦ä¹ ](http://it.sohu.com/20170124/n479480999.shtml)è¿™ç¯‡æ–‡ç« æ˜¯å¯¹Martin Gornerçš„ç®€æ˜“æ•™ç¨‹çš„åŸæ–‡ç¿»è¯‘ï¼Œæˆ‘ä»¬æš‚æ—¶ä¸è¦æ±‚äº†è§£TensorFlowèƒŒåå¤æ‚çš„ç†è®ºï¼Œæˆ‘ä»¬å…ˆè·Ÿéšè¿™ç¯‡ç®€æ˜“æ•™ç¨‹ç©ä¸€æŠŠTensorFlowçš„æ‰‹å†™æ•°å­—è¯†åˆ«ã€‚

å¦‚æœä½ æƒ³æ·±å…¥äº†è§£è¿™æœ¬åçš„åŸç†çš„è¯ï¼Œå¯ä»¥æŸ¥çœ‹å“ˆå°”æ»¨å·¥ä¸šå¤§å­¦ç¤¾ä¼šè®¡ç®—ä¸ä¿¡æ¯æ£€ç´¢ç ”ç©¶ä¸­å¿ƒç¿»è¯‘çš„[ã€Šç¥ç»ç½‘ç»œä¸æ·±åº¦å­¦ä¹ ã€‹](https://www.gitbook.com/book/hit-scir/neural-networks-and-deep-learning-zh_cn/details)è¿™æœ¬ä¹¦ï¼Œè¯¥ä¹¦ç¿»è¯‘è‡ª[Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/)çš„ä¸­æ–‡ç¿»è¯‘ï¼ŒåŸæ–‡ä½œè€… Michael Nielsenï¼Œè€Œä¸”è¿™è¿˜æ˜¯ä¸€æœ¬å…è´¹çš„ç”µå­ä¹¦ï¼Œè¯¥ä¹¦ä¸­ç³»ç»Ÿè®²è§£äº†[ä½¿ç”¨ç¥ç»ç½‘ç»œè¯†åˆ«æ‰‹å†™æ•°å­—](https://hit-scir.gitbooks.io/neural-networks-and-deep-learning-zh_cn/content/chap1/c1s0.html)èƒŒåçš„åŸç†ã€‚è¯¥ä¹¦æ‰˜ç®¡åœ¨GitBookä¸Šï¼Œä½ å¯ä»¥ç‚¹å‡»[è¿™é‡Œ](http://olz1di9xf.bkt.clouddn.com/neural-networks-and-deep-learning-zh_cn.pdf)ç›´æ¥ä¸‹è½½è¯¥ä¹¦ä¸­æ–‡ç‰ˆçš„PDFã€‚

## å‡†å¤‡

**ä¸‹è½½ä»£ç **

è¿™ä¸ªä»£ç ä»“åº“é‡ŒåŒ…å«äº†æ‰‹å†™æ•°å­—è¯†åˆ«å’Œä¸‹è½½ä¾èµ–çš„è®­ç»ƒæ•°æ®çš„ä»£ç ï¼Œæˆ‘ä»¬å°†åªç”¨åˆ°`mnist_1.0_softmax.py`è¿™ä¸€ä¸ªä»£ç æ–‡ä»¶ã€‚

```shell
git clone https://github.com/martin-gorner/tensorflow-mnist-tutorial.git
```

ä¸‹è½½å®Œåï¼Œå¯ä»¥çœ‹åˆ°æœ‰ä¸€ä¸ª**INSTALL.txt**ï¼Œè¿™ç¯‡æ–‡ç« æ˜¯è¿è¡Œä»£ç æ‰€å¿…éœ€çš„ç¯å¢ƒè¦æ±‚è¯´æ˜ã€‚

**å®‰è£…TensorFlow**

æˆ‘ä¹‹å‰å†™è¿‡è¯¦ç»†çš„TensorFlowå®‰è£…æ•™ç¨‹[TensorFlowå®æˆ˜ï¼ˆæ‰äº‘éƒ‘æ³½å®‡è‘—ï¼‰è¯»ä¹¦ç¬”è®°â€”â€”ç¬¬äºŒç« TensorFlowç¯å¢ƒæ­å»º](http://rootsongjc.github.io/blogs/tensorflow-practice-02/)ï¼Œè¿™ç¯‡æ–‡ç« ä¸­ä¸»è¦è®²æ€æ ·åœ¨dockeré‡Œå®‰è£…TensorFlowã€‚

æˆ‘ä½¿ç”¨çš„Macè€Œä¸”è¿˜æ˜¯python2.7ï¼Œæ‰€ä»¥æˆ‘è¿™æ ·å®‰è£…ï¼š

```
pip install --upgrade tensorflow --user -U
pip install --upgrade matplotlib --user -U
```

## è¿è¡Œç¤ºä¾‹

è¿è¡Œæ‰‹å†™æ•°å­—è®­ç»ƒç¤ºä¾‹ã€‚

```shell
python mnist_1.0_softmax.py
```

è¿è¡Œè¿‡ç¨‹ä¸­ä½ ä¼šçœ‹åˆ°ä¸€å¤§æ®µè¾“å‡ºï¼š

```
Collecting matplotlib
  Downloading matplotlib-2.0.0-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (12.8MB)
    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12.8MB 26kB/s 
Requirement already up-to-date: pyparsing!=2.0.0,!=2.0.4,!=2.1.2,!=2.1.6,>=1.5.6 in /Users/jimmy/Library/Python/2.7/lib/python/site-packages (from matplotlib)
Requirement already up-to-date: numpy>=1.7.1 in /Users/jimmy/Library/Python/2.7/lib/python/site-packages (from matplotlib)
Collecting functools32 (from matplotlib)
  Downloading functools32-3.2.3-2.zip
Collecting pytz (from matplotlib)
  Downloading pytz-2017.2-py2.py3-none-any.whl (484kB)
    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 491kB 33kB/s 
Requirement already up-to-date: six>=1.10 in /Users/jimmy/Library/Python/2.7/lib/python/site-packages (from matplotlib)
Collecting cycler>=0.10 (from matplotlib)
  Downloading cycler-0.10.0-py2.py3-none-any.whl
Collecting subprocess32 (from matplotlib)
  Downloading subprocess32-3.2.7.tar.gz (54kB)
    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 26kB/s 
Collecting python-dateutil (from matplotlib)
  Downloading python_dateutil-2.6.0-py2.py3-none-any.whl (194kB)
    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 194kB 45kB/s 
Building wheels for collected packages: functools32, subprocess32
  Running setup.py bdist_wheel for functools32 ... done
  Stored in directory: /Users/jimmy/Library/Caches/pip/wheels/3c/d0/09/cd78d0ff4d6cfecfbd730782a7815a4571cd2cd4d2ed6e69d9
  Running setup.py bdist_wheel for subprocess32 ... done
  Stored in directory: /Users/jimmy/Library/Caches/pip/wheels/7d/4c/a4/ce9ceb463dae01f4b95e670abd9afc8d65a45f38012f8030cc
Successfully built functools32 subprocess32
Installing collected packages: functools32, pytz, cycler, subprocess32, python-dateutil, matplotlib
Successfully installed cycler-0.10.0 functools32-3.2.3.post2 matplotlib-2.0.0 python-dateutil-2.6.0 pytz-2017.2 subprocess32-3.2.7
```

æˆ‘ä»¬çœ‹åˆ°è¿™ä¸ªè¿‡ç¨‹ä¸­ä¸‹è½½äº†ä¸€äº›pythonä¾èµ–åº“å¦‚ï¼š

- matplotlib
- pytz
- subprocess32
- cycler
- python_dateutil
- functools32

æ‰€æœ‰çš„ä¾èµ–éƒ½ä¸‹è½½å®Œæˆä¹‹åï¼Œå°±ä¼šå¼¹å‡ºä¸€ä¸ªçª—å£ï¼ŒåŒæ—¶åå°ä¹Ÿä¼šåœ¨ä¸æ–­æ»šåŠ¨æ˜¾ç¤ºè®­ç»ƒçš„é˜¶æ®µï¼Œç›´åˆ°2001æ­¥ï¼Œå¦‚å›¾ï¼š

![tensorflow-mnist-01](http://olz1di9xf.bkt.clouddn.com/tensorflow-mnist-01.jpg)

æ­£è§„çš„TensorFlowé¡¹ç›®ä¼šä½¿ç”¨**TensorBoard**ä½œå¯è§†åŒ–ï¼Œæˆ‘ä»¬ç”¨**matplotlib**ä½œä¸ºæ›¿ä»£ã€‚

è‡³æ­¤æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ç»“æŸäº†ï¼Œä½†æ˜¯æˆ‘ä»¬è¿˜ä¸æ˜ç™½è¿™ä¸ªçª—å£é‡Œçš„6ä¸ªå›¾åˆ†åˆ«è¡¨ç¤ºçš„å«ä¹‰ï¼Œä¸‹é¢å°†ä¾æ¬¡ä½œå‡ºè§£é‡Šã€‚

## ä»£ç 

æ•´ä¸ª`mnist_1.0_softmax.py `ä»£ç å¹¶ä¸å¤æ‚ï¼Œä¸ç®—æ³¨é‡Šçš„è¯åªæœ‰36è¡Œã€‚

```python
import tensorflow as tf
import tensorflowvisu
from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets
tf.set_random_seed(0)

# neural network with 1 layer of 10 softmax neurons
#
# Â· Â· Â· Â· Â· Â· Â· Â· Â· Â·       (input data, flattened pixels)       X [batch, 784]        # 784 = 28 * 28
# \x/x\x/x\x/x\x/x\x/    -- fully connected layer (softmax)      W [784, 10]     b[10]
#   Â· Â· Â· Â· Â· Â· Â· Â·                                              Y [batch, 10]

# The model is:
#
# Y = softmax( X * W + b)
#              X: matrix for 100 grayscale images of 28x28 pixels, flattened (there are 100 images in a mini-batch)
#              W: weight matrix with 784 lines and 10 columns
#              b: bias vector with 10 dimensions
#              +: add with broadcasting: adds the vector to each line of the matrix (numpy)
#              softmax(matrix) applies softmax on each line
#              softmax(line) applies an exp to each value then divides by the norm of the resulting line
#              Y: output matrix with 100 lines and 10 columns

# Download images and labels into mnist.test (10K images+labels) and mnist.train (60K images+labels)
mnist = read_data_sets("data", one_hot=True, reshape=False, validation_size=0)

# input X: 28x28 grayscale images, the first dimension (None) will index the images in the mini-batch
X = tf.placeholder(tf.float32, [None, 28, 28, 1])
# correct answers will go here
Y_ = tf.placeholder(tf.float32, [None, 10])
# weights W[784, 10]   784=28*28
W = tf.Variable(tf.zeros([784, 10]))
# biases b[10]
b = tf.Variable(tf.zeros([10]))

# flatten the images into a single line of pixels
# -1 in the shape definition means "the only possible dimension that will preserve the number of elements"
XX = tf.reshape(X, [-1, 784])

# The model
Y = tf.nn.softmax(tf.matmul(XX, W) + b)

# loss function: cross-entropy = - sum( Y_i * log(Yi) )
#                           Y: the computed output vector
#                           Y_: the desired output vector

# cross-entropy
# log takes the log of each element, * multiplies the tensors element by element
# reduce_mean will add all the components in the tensor
# so here we end up with the total cross-entropy for all images in the batch
cross_entropy = -tf.reduce_mean(Y_ * tf.log(Y)) * 1000.0  # normalized for batches of 100 images,
                                                          # *10 because  "mean" included an unwanted division by 10

# accuracy of the trained model, between 0 (worst) and 1 (best)
correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

# training, learning rate = 0.005
train_step = tf.train.GradientDescentOptimizer(0.005).minimize(cross_entropy)

# matplotlib visualisation
allweights = tf.reshape(W, [-1])
allbiases = tf.reshape(b, [-1])
I = tensorflowvisu.tf_format_mnist_images(X, Y, Y_)  # assembles 10x10 images by default
It = tensorflowvisu.tf_format_mnist_images(X, Y, Y_, 1000, lines=25)  # 1000 images on 25 lines
datavis = tensorflowvisu.MnistDataVis()

# init
init = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init)


# You can call this function in a loop to train the model, 100 images at a time
def training_step(i, update_test_data, update_train_data):

    # training on batches of 100 images with 100 labels
    batch_X, batch_Y = mnist.train.next_batch(100)

    # compute training values for visualisation
    if update_train_data:
        a, c, im, w, b = sess.run([accuracy, cross_entropy, I, allweights, allbiases], feed_dict={X: batch_X, Y_: batch_Y})
        datavis.append_training_curves_data(i, a, c)
        datavis.append_data_histograms(i, w, b)
        datavis.update_image1(im)
        print(str(i) + ": accuracy:" + str(a) + " loss: " + str(c))

    # compute test values for visualisation
    if update_test_data:
        a, c, im = sess.run([accuracy, cross_entropy, It], feed_dict={X: mnist.test.images, Y_: mnist.test.labels})
        datavis.append_test_curves_data(i, a, c)
        datavis.update_image2(im)
        print(str(i) + ": ********* epoch " + str(i*100//mnist.train.images.shape[0]+1) + " ********* test accuracy:" + str(a) + " test loss: " + str(c))

    # the backpropagation training step
    sess.run(train_step, feed_dict={X: batch_X, Y_: batch_Y})


datavis.animate(training_step, iterations=2000+1, train_data_update_freq=10, test_data_update_freq=50, more_tests_at_start=True)

# to save the animation as a movie, add save_movie=True as an argument to datavis.animate
# to disable the visualisation use the following line instead of the datavis.animate line
# for i in range(2000+1): training_step(i, i % 50 == 0, i % 10 == 0)

print("max test accuracy: " + str(datavis.get_max_test_accuracy()))

# final max test accuracy = 0.9268 (10K iterations). Accuracy should peak above 0.92 in the first 2000 iterations.
```

## çª—å£ä¸­çš„å›¾ç‰‡è¯´æ˜

æˆ‘ä»¬åˆ†åˆ«æ¥çœ‹ä¸‹MNISTçª—å£ä¸­çš„6ä¸ªPanelã€‚

### Training Digits

æ­¤**DataSet**ä¸­ä¸€å…±æœ‰50000ä¸ª<u>è®­ç»ƒæ•°å­—</u>ï¼Œæ¯æ¬¡**Iteration**é€å…¥100ä¸ªæ•°å­—ä½œä¸ºå¾ªç¯ï¼Œ500æ¬¡è¿­ä»£åå¯ä»¥å°†æ‰€æœ‰æ•°å­—è®­ç»ƒä¸€æ¬¡ï¼Œå«åšä¸€ä¸ª**Epoch**ã€‚

ä¸Šå›¾ä¸­ç™½è‰²èƒŒæ™¯çš„æ•°å­—è¡¨ç¤ºè¯†åˆ«æ­£ç¡®çš„ï¼Œçº¢è‰²èƒŒæ™¯çš„éƒ¨åˆ†è¡¨ç¤ºè¯†åˆ«é”™è¯¯çš„ï¼Œæ¯ä¸ªæ•°å­—å·¦è¾¹ä¸‹æ ‡è¡¨ç¤ºåº”è¯¥è¢«è¯†åˆ«æˆçš„æ­£ç¡®ç»“æœï¼Œæ•°å­—å³è¾¹çš„ä¸‹æ ‡æ˜¯è¯†åˆ«é”™è¯¯çš„ç»“æœã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![training digits](http://olz1di9xf.bkt.clouddn.com/tensorflow-mnist-panel-01.jpg)

### Test Digits

æ­¤å¤–ä¹Ÿä¸èƒ½å…‰æœ‰è®­ç»ƒæ•°å­—å§ï¼ŒMNISTæ•°æ®é›†ä¸­è¿˜æœ‰10000ä¸ªæµ‹è¯•æ•°å­—ï¼Œæ­¤å¤„ä½ èƒ½çœ‹åˆ°æ¯ä¸ªæ•°å­—å¯¹åº”çš„å¤§çº¦ 1000 ç§ä¹¦å†™å½¢å¼ï¼Œå…¶ä¸­æ‰€æœ‰é”™è¯¯è¯†åˆ«çš„æ•°å­—åˆ—åœ¨é¡¶éƒ¨ï¼ˆæœ‰çº¢è‰²èƒŒæ™¯ï¼‰ã€‚å·¦è¾¹çš„åˆ»åº¦ä¼šç»™ä½ ä¸€ä¸ªç²—ç•¥çš„åˆ†è¾¨ç‡ç²¾ç¡®åº¦ï¼ˆæ­£ç¡®è¯†åˆ«çš„ç™¾åˆ†æ¯”ï¼‰ã€‚å¦‚ä¸‹å›¾ï¼š

![test digits](http://olz1di9xf.bkt.clouddn.com/tensorflow-mnist-panel-02.jpg)

å¯ä»¥çœ‹åˆ°ç»è¿‡2000è½®çš„è®­ç»ƒåï¼Œå·²ç»å¯¹æ‰‹å†™æ•°å­—çš„è¯†åˆ«ç‡è¾¾åˆ°äº†92%ã€‚

### Cross Entropy Loss

ä¸ºäº†é©±åŠ¨è®­ç»ƒï¼Œæˆ‘ä»¬æ¥å®šä¹‰**æŸå¤±å‡½æ•°**ï¼Œå³<u>ä¸€ä¸ªå±•ç¤ºå‡ºç³»ç»Ÿæ•°å­—è¯†åˆ«èƒ½åŠ›æœ‰å¤šç³Ÿçš„å€¼</u>ï¼Œå¹¶ä¸”ç³»ç»Ÿä¼šå°½åŠ›å°†å…¶æœ€å°åŒ–ã€‚æŸå¤±å‡½æ•°ï¼ˆloss functionï¼Œæ­¤å¤„ä¸º[äº¤å‰ç†µ](https://hit-scir.gitbooks.io/neural-networks-and-deep-learning-zh_cn/content/chap3/c3s1.html)ï¼‰çš„é€‰æ‹©ç¨åä¼šåšå‡ºè§£é‡Šã€‚ä½ ä¼šçœ‹åˆ°ï¼Œéšç€è®­ç»ƒçš„è¿›è¡Œï¼Œè®­ç»ƒå’Œæµ‹è¯•æ•°æ®çš„æŸå¤±ä¼šå‡å°‘ï¼Œè€Œè¿™ä¸ªç°è±¡æ˜¯å¥½çš„ï¼Œæ„å‘³ç€ç¥ç»ç½‘ç»œæ­£åœ¨å­¦ä¹ ã€‚X è½´è¡¨ç¤ºäº†å­¦ä¹ è¿‡ç¨‹ä¸­çš„è¿­ä»£ã€‚å¦‚ä¸‹å›¾ï¼š

![cross entropy loss](http://olz1di9xf.bkt.clouddn.com/tensorflow-mnist-panel-03.jpg)

### Accuracy

è¿™ä¸ªå‡†ç¡®åº¦åªæ˜¯æ­£ç¡®è¯†åˆ«çš„æ•°å­—çš„ç™¾åˆ†æ¯”ï¼Œæ˜¯åœ¨è®­ç»ƒå’Œæµ‹è¯•é›†ä¸Šè®¡ç®—å‡ºçš„ã€‚å¦‚æœè®­ç»ƒé¡ºåˆ©ï¼Œå®ƒä¾¿ä¼šä¸Šå‡ã€‚

![accuratcy](http://olz1di9xf.bkt.clouddn.com/tensorflow-mnist-panel-04.jpg)

### Weight && Biases

æœ€åçš„ä¸¤å¹…å›¾è¡¨è¯´æ˜äº†å†…éƒ¨å˜é‡æ‰€å–çš„æ‰€æœ‰å€¼çš„æ‰©å±•ï¼Œå³éšè®­ç»ƒè¿›è¡Œè€Œå˜åŒ–çš„æƒé‡å’Œåç½®ã€‚æ¯”å¦‚åç½®ä» 0 å¼€å§‹ï¼Œä¸”æœ€ç»ˆå¾—åˆ°çš„å€¼å¤§è‡´å‡åŒ€åœ°åˆ†å¸ƒåœ¨-1.5 å’Œ 1.5 ä¹‹é—´ã€‚å¦‚æœç³»ç»Ÿä¸èƒ½å¾ˆå¥½åœ°æ”¶æ•›ï¼Œé‚£ä¹ˆè¿™äº›å›¾å¯èƒ½æœ‰ç”¨ã€‚å€˜è‹¥ä½ å‘ç°æƒé‡å’Œåå·®æ‰©å±•åˆ°ä¸Šç™¾æˆ–ä¸Šåƒï¼Œé‚£ä¹ˆå°±å¯èƒ½æœ‰é—®é¢˜äº†ã€‚

![weight](http://olz1di9xf.bkt.clouddn.com/tensorflow-mnist-panel-05.jpg)

![biases](http://olz1di9xf.bkt.clouddn.com/tensorflow-mnist-panel-06.jpg)

å‰©ä¸‹çš„éƒ¨åˆ†å°±æ˜¯ç†è®ºè®²è§£äº†ï¼Œå…ˆå¤åˆ¶è¿‡æ¥ï¼ŒæœŸå¾…æœ‰æœä¸€æ—¥æˆ‘èƒ½çœ‹æ‡‚å§ğŸ˜„

### ç†è®º : å•å±‚ç¥ç»ç½‘ç»œ

MNIST æ•°æ®é›†ä¸­ï¼Œæ‰‹å†™æ•°å­—æ˜¯ 28x28 åƒç´ çš„ç°åº¦å›¾åƒã€‚å°†å®ƒä»¬è¿›è¡Œåˆ†ç±»çš„æœ€ç®€å•çš„æ–¹æ³•å°±æ˜¯ä½¿ç”¨ 28x28=784 ä¸ªåƒç´ ä½œä¸ºå•å±‚ç¥ç»ç½‘ç»œçš„è¾“å…¥ã€‚

ã€€ã€€![img](http://img.mp.itc.cn/upload/20170124/5070df2db57143eabd8549e038c95735_th.jpeg)

ç¥ç»ç½‘ç»œä¸­çš„æ¯ä¸ªã€Œç¥ç»å…ƒã€å¯¹å…¶æ‰€æœ‰çš„è¾“å…¥è¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œå¹¶æ·»åŠ ä¸€ä¸ªè¢«ç§°ä¸ºã€Œåç½®ï¼ˆbiasï¼‰ã€çš„å¸¸æ•°ï¼Œç„¶åé€šè¿‡ä¸€äº›éçº¿æ€§æ¿€æ´»å‡½æ•°æ¥åé¦ˆç»“æœã€‚

ä¸ºäº†å°†æ•°å­—åˆ†ä¸º 10 ç±»ï¼ˆ0 åˆ° 9ï¼‰ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªå…·æœ‰ 10 ä¸ªè¾“å‡ºç¥ç»å…ƒçš„å•å±‚ç¥ç»ç½‘ç»œã€‚å¯¹äºåˆ†ç±»é—®é¢˜ï¼Œsoftmax æ˜¯ä¸€ä¸ªä¸é”™çš„æ¿€æ´»å‡½æ•°ã€‚é€šè¿‡å–æ¯ä¸ªå…ƒç´ çš„æŒ‡æ•°ï¼Œç„¶åå½’ä¸€åŒ–å‘é‡ï¼ˆä½¿ç”¨ä»»æ„çš„èŒƒæ•°ï¼ˆnormï¼‰ï¼Œæ¯”å¦‚å‘é‡çš„æ™®é€šæ¬§å‡ é‡Œå¾—è·ç¦»ï¼‰ä»è€Œå°† softmax åº”ç”¨äºå‘é‡ã€‚

![img](http://img.mp.itc.cn/upload/20170124/7648d231901a468a99cb9a849e8630a5_th.png)

é‚£ä¹ˆä¸ºä»€ä¹ˆã€Œsoftmaxã€ä¼šè¢«ç§°ä¸º softmax å‘¢ï¼ŸæŒ‡æ•°æ˜¯ä¸€ç§éª¤å¢çš„å‡½æ•°ã€‚è¿™å°†åŠ å¤§å‘é‡ä¸­æ¯ä¸ªå…ƒç´ çš„å·®å¼‚ã€‚å®ƒä¹Ÿä¼šè¿…é€Ÿåœ°äº§ç”Ÿä¸€ä¸ªå·¨å¤§çš„å€¼ã€‚ç„¶åï¼Œå½“è¿›è¡Œå‘é‡çš„æ ‡å‡†åŒ–æ—¶ï¼Œæ”¯é…èŒƒæ•°ï¼ˆnormï¼‰çš„æœ€å¤§çš„å…ƒç´ å°†ä¼šè¢«æ ‡å‡†åŒ–ä¸ºä¸€ä¸ªæ¥è¿‘ 1 çš„æ•°å­—ï¼Œå…¶ä»–çš„å…ƒç´ å°†ä¼šè¢«ä¸€ä¸ªè¾ƒå¤§çš„å€¼åˆ†å‰²å¹¶è¢«æ ‡å‡†åŒ–ä¸ºä¸€ä¸ªæ¥è¿‘ 0 çš„æ•°å­—ã€‚æ‰€å¾—åˆ°çš„å‘é‡æ¸…æ¥šåœ°æ˜¾ç¤ºå‡ºäº†å“ªä¸ªæ˜¯å…¶æœ€å¤§çš„å€¼ï¼Œå³ã€Œmaxã€ï¼Œä½†æ˜¯å´åˆä¿ç•™äº†å…¶å€¼çš„åŸå§‹çš„ç›¸å¯¹æ’åˆ—é¡ºåºï¼Œå› æ­¤å³ä¸ºã€Œsoftã€ã€‚

![img](http://img.mp.itc.cn/upload/20170124/c85a5d9f37f045ceb8b7b0b457159782_th.jpeg)

æˆ‘ä»¬ç°åœ¨å°†ä½¿ç”¨çŸ©é˜µä¹˜æ³•å°†è¿™ä¸ªå•å±‚çš„ç¥ç»å…ƒçš„è¡Œä¸ºæ€»ç»“è¿›ä¸€ä¸ªç®€å•çš„å…¬å¼å½“ä¸­ã€‚è®©æˆ‘ä»¬ç›´æ¥è¿™æ ·åšï¼š100 ä¸ªå›¾åƒçš„ã€Œmini-batchã€ä½œä¸ºè¾“å…¥ï¼Œäº§ç”Ÿ 100 ä¸ªé¢„æµ‹ï¼ˆ10 å…ƒç´ å‘é‡ï¼‰ä½œä¸ºè¾“å‡ºã€‚

ä½¿ç”¨åŠ æƒçŸ©é˜µ W çš„ç¬¬ä¸€åˆ—æƒé‡ï¼Œæˆ‘ä»¬è®¡ç®—ç¬¬ä¸€ä¸ªå›¾åƒæ‰€æœ‰åƒç´ çš„åŠ æƒå’Œã€‚è¯¥å’Œå¯¹åº”äºç¬¬ä¸€ç¥ç»å…ƒã€‚ä½¿ç”¨ç¬¬äºŒåˆ—æƒé‡ï¼Œæˆ‘ä»¬å¯¹ç¬¬äºŒä¸ªç¥ç»å…ƒè¿›è¡ŒåŒæ ·çš„æ“ä½œï¼Œç›´åˆ°ç¬¬ 10 ä¸ªç¥ç»å…ƒã€‚ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥å¯¹å‰©ä½™çš„ 99 ä¸ªå›¾åƒé‡å¤æ“ä½œã€‚å¦‚æœæˆ‘ä»¬æŠŠä¸€ä¸ªåŒ…å« 100 ä¸ªå›¾åƒçš„çŸ©é˜µç§°ä¸º Xï¼Œé‚£ä¹ˆæˆ‘ä»¬çš„ 10 ä¸ªç¥ç»å…ƒåœ¨è¿™ 100 å¼ å›¾åƒä¸Šçš„åŠ æƒå’Œå°±æ˜¯ç®€å•çš„ X.Wï¼ˆçŸ©é˜µä¹˜æ³•ï¼‰ã€‚

æ¯ä¸€ä¸ªç¥ç»å…ƒéƒ½å¿…é¡»æ·»åŠ å…¶åç½®ï¼ˆä¸€ä¸ªå¸¸æ•°ï¼‰ã€‚å› ä¸ºæˆ‘ä»¬æœ‰ 10 ä¸ªç¥ç»å…ƒï¼Œæˆ‘ä»¬åŒæ ·æ‹¥æœ‰ 10 ä¸ªåç½®å¸¸æ•°ã€‚æˆ‘ä»¬å°†è¿™ä¸ª 10 ä¸ªå€¼çš„å‘é‡ç§°ä¸º bã€‚å®ƒå¿…é¡»è¢«æ·»åŠ åˆ°å…ˆå‰è®¡ç®—çš„çŸ©é˜µä¸­çš„æ¯ä¸€è¡Œå½“ä¸­ã€‚ä½¿ç”¨ä¸€ä¸ªç§°ä¸º "broadcasting" çš„é­”æ³•ï¼Œæˆ‘ä»¬å°†ä¼šç”¨ä¸€ä¸ªç®€å•çš„åŠ å·å†™å‡ºå®ƒã€‚

ã€ŒBroadcastingã€æ˜¯ Python å’Œ numpyï¼ˆPython çš„ç§‘å­¦è®¡ç®—åº“ï¼‰çš„ä¸€ä¸ªæ ‡å‡†æŠ€å·§ã€‚å®ƒæ‰©å±•äº†å¯¹ä¸å…¼å®¹ç»´åº¦çš„çŸ©é˜µè¿›è¡Œæ­£å¸¸æ“ä½œçš„æ–¹å¼ã€‚ã€ŒBroadcasting addã€æ„å‘³ç€ã€Œå¦‚æœä½ å› ä¸ºä¸¤ä¸ªçŸ©é˜µç»´åº¦ä¸åŒçš„åŸå› è€Œä¸èƒ½å°†å…¶ç›¸åŠ ï¼Œé‚£ä¹ˆä½ å¯ä»¥æ ¹æ®éœ€è¦å°è¯•å¤åˆ¶ä¸€ä¸ªå°çš„çŸ©é˜µä½¿å…¶å·¥ä½œã€‚ã€

æˆ‘ä»¬æœ€ç»ˆåº”ç”¨ softmax æ¿€æ´»å‡½æ•°å¹¶ä¸”å¾—åˆ°ä¸€ä¸ªæè¿°å•å±‚ç¥ç»ç½‘ç»œçš„å…¬å¼ï¼Œå¹¶å°†å…¶åº”ç”¨äº 100 å¼ å›¾åƒï¼š

![img](http://img.mp.itc.cn/upload/20170124/cd007da75f714c96ade9a4e4c0187bfa_th.jpeg)

é¡ºä¾¿è¯´ä¸€ä¸‹ï¼Œä»€ä¹ˆæ˜¯ã€Œtensorï¼ˆå¼ é‡ï¼‰ã€ï¼Ÿ

ã€Œå¼ é‡ï¼ˆtensorï¼‰ã€åƒä¸€ä¸ªçŸ©é˜µï¼Œä½†æ˜¯å´æœ‰ç€ä»»æ„æ•°é‡çš„ç»´åº¦ã€‚ä¸€ä¸ª 1 ç»´çš„å¼ é‡æ˜¯ä¸€ä¸ªå‘é‡ã€‚ä¸€ä¸ªäºŒç»´çš„å¼ é‡æ˜¯ä¸€ä¸ªçŸ©é˜µã€‚ç„¶åä½ å¯ä»¥æœ‰ 3, 4, 5 æˆ–è€…æ›´å¤šç»´çš„å¼ é‡ã€‚

### ç†è®ºï¼šæ¢¯åº¦ä¸‹é™

ç°åœ¨æˆ‘ä»¬çš„ç¥ç»ç½‘ç»œä»è¾“å…¥å›¾åƒä¸­äº§ç”Ÿé¢„æµ‹ï¼Œæˆ‘ä»¬éœ€è¦çŸ¥é“å®ƒä»¬å¯ä»¥åšåˆ°ä»€ä¹ˆæ ·çš„ç¨‹åº¦ï¼Œå³åœ¨æˆ‘ä»¬çŸ¥é“çš„äº‹å®å’Œç½‘ç»œçš„é¢„æµ‹ä¹‹é—´åˆ°åº•æœ‰å¤šå¤§çš„è·ç¦»ã€‚è¯·è®°ä½ï¼Œæˆ‘ä»¬å¯¹äºè¿™ä¸ªæ•°æ®é›†ä¸­çš„æ‰€æœ‰å›¾åƒéƒ½æœ‰ä¸€ä¸ªçœŸå®çš„æ ‡ç­¾ã€‚

ä»»ä½•ä¸€ç§å®šä¹‰çš„è·ç¦»éƒ½å¯ä»¥è¿›è¡Œè¿™æ ·çš„æ“ä½œï¼Œæ™®é€šæ¬§å‡ é‡Œå¾—è·ç¦»æ˜¯å¯ä»¥çš„ï¼Œä½†æ˜¯å¯¹äºåˆ†ç±»é—®é¢˜ï¼Œè¢«ç§°ä¸ºã€Œäº¤å‰ç†µï¼ˆcross-entropyï¼‰ã€çš„è·ç¦»æ›´åŠ æœ‰æ•ˆã€‚

![img](http://img.mp.itc.cn/upload/20170124/9fe5ab61209c490297769b729a471c81_th.jpeg)

ã€Œone-hotã€ç¼–ç æ„å‘³ç€ä½ ä½¿ç”¨ä¸€ä¸ª 10 ä¸ªå€¼çš„å‘é‡ï¼Œå…¶ä¸­é™¤äº†ç¬¬ 6 ä¸ªå€¼ä¸º 1 ä»¥å¤–çš„æ‰€æœ‰å€¼éƒ½æ˜¯ 0ã€‚è¿™éå¸¸æ–¹ä¾¿ï¼Œå› ä¸ºè¿™æ ·çš„æ ¼å¼å’Œæˆ‘ä»¬ç¥ç»ç½‘ç»œé¢„æµ‹è¾“å‡ºçš„æ ¼å¼éå¸¸ç›¸ä¼¼ï¼ŒåŒæ—¶å®ƒä¹Ÿä½œä¸ºä¸€ä¸ª 10 å€¼çš„å‘é‡ã€‚

ã€Œè®­ç»ƒã€ä¸€ä¸ªç¥ç»ç½‘ç»œå®é™…ä¸Šæ„å‘³ç€ä½¿ç”¨è®­ç»ƒå›¾åƒå’Œæ ‡ç­¾æ¥è°ƒæ•´æƒé‡å’Œåç½®ï¼Œä»¥ä¾¿æœ€å°åŒ–äº¤å‰ç†µæŸå¤±å‡½æ•°ã€‚å®ƒæ˜¯è¿™æ ·å·¥ä½œçš„ã€‚

äº¤å‰ç†µæ˜¯ä¸€ä¸ªå…³äºæƒé‡ã€åç½®ã€è®­ç»ƒå›¾åƒçš„åƒç´ å’Œå…¶å·²çŸ¥æ ‡ç­¾çš„å‡½æ•°ã€‚

å¦‚æœæˆ‘ä»¬ç›¸å¯¹äºæ‰€æœ‰çš„æƒé‡å’Œæ‰€æœ‰çš„åç½®è®¡ç®—äº¤å‰ç†µçš„åå¯¼æ•°ï¼Œæˆ‘ä»¬å°±å¾—åˆ°ä¸€ä¸ªå¯¹äºç»™å®šå›¾åƒã€æ ‡ç­¾å’Œå½“å‰æƒé‡å’Œåç½®çš„ã€Œæ¢¯åº¦ã€ã€‚è¯·è®°ä½ï¼Œæˆ‘ä»¬æœ‰ 7850 ä¸ªæƒé‡å’Œåç½®ï¼Œæ‰€ä»¥è®¡ç®—æ¢¯åº¦éœ€è¦å¤§é‡çš„å·¥ä½œã€‚å¹¸è¿çš„æ˜¯ï¼ŒTensorFlow å¯ä»¥æ¥å¸®æˆ‘ä»¬åšè¿™é¡¹å·¥ä½œã€‚

æ¢¯åº¦çš„æ•°å­¦æ„ä¹‰åœ¨äºå®ƒæŒ‡å‘ã€Œä¸Šï¼ˆupï¼‰ã€ã€‚å› ä¸ºæˆ‘ä»¬æƒ³è¦åˆ°è¾¾ä¸€ä¸ªäº¤å‰ç†µä½çš„åœ°æ–¹ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±å»å‘ç›¸åçš„æ–¹å‘ã€‚æˆ‘ä»¬ç”¨ä¸€å°éƒ¨åˆ†çš„æ¢¯åº¦æ›´æ–°æƒé‡å’Œåç½®å¹¶ä¸”ä½¿ç”¨ä¸‹ä¸€æ‰¹è®­ç»ƒå›¾åƒå†æ¬¡åšåŒæ ·çš„äº‹æƒ…ã€‚æˆ‘ä»¬å¸Œæœ›çš„æ˜¯ï¼Œè¿™å¯ä»¥ä½¿æˆ‘ä»¬åˆ°è¾¾äº¤å‰ç†µæœ€å°çš„å‡¹ç‚¹çš„ä½éƒ¨ã€‚

![img](http://img.mp.itc.cn/upload/20170124/b90ff98a395b46e392c21c6ebca0c7d6_th.jpeg)

åœ¨è¿™å‰¯å›¾ç‰‡å½“ä¸­ï¼Œäº¤å‰ç†µè¢«è¡¨ç¤ºä¸ºä¸€ä¸ªå…·æœ‰ä¸¤ä¸ªæƒé‡çš„å‡½æ•°ã€‚äº‹å®ä¸Šï¼Œè¿˜æœ‰æ›´å¤šã€‚æ¢¯åº¦ä¸‹é™ç®—æ³•éµå¾ªç€ä¸€ä¸ªæœ€é™¡çš„å¡åº¦ä¸‹é™åˆ°å±€éƒ¨æœ€å°å€¼çš„è·¯å¾„ã€‚è®­ç»ƒå›¾åƒåœ¨æ¯ä¸€æ¬¡è¿­ä»£ä¸­åŒæ ·ä¼šè¢«æ”¹å˜ï¼Œè¿™ä½¿å¾—æˆ‘ä»¬å‘ç€ä¸€ä¸ªé€‚ç”¨äºæ‰€æœ‰å›¾åƒçš„å±€éƒ¨æœ€å°å€¼æ”¶æ•›ã€‚

ã€Œå­¦ä¹ ç‡ï¼ˆlearning rateï¼‰ã€ï¼š åœ¨æ•´ä¸ªæ¢¯åº¦çš„é•¿åº¦ä¸Šï¼Œä½ ä¸èƒ½åœ¨æ¯ä¸€æ¬¡è¿­ä»£çš„æ—¶å€™éƒ½å¯¹æƒé‡å’Œåç½®è¿›è¡Œæ›´æ–°ã€‚è¿™å°±ä¼šåƒæ˜¯ä½ ç©¿ç€ä¸ƒé‡Œé´å´è¯•å›¾åˆ°è¾¾ä¸€ä¸ªå±±è°·çš„åº•éƒ¨ã€‚ä½ ä¼šç›´æ¥ä»å±±è°·çš„ä¸€è¾¹åˆ°è¾¾å¦ä¸€è¾¹ã€‚ä¸ºäº†åˆ°è¾¾åº•éƒ¨ï¼Œä½ éœ€è¦ä¸€äº›æ›´å°çš„æ­¥ä¼ï¼Œå³åªä½¿ç”¨æ¢¯åº¦çš„ä¸€éƒ¨åˆ†ï¼Œé€šå¸¸åœ¨ 1/1000 åŒºåŸŸä¸­ã€‚æˆ‘ä»¬ç§°è¿™ä¸ªéƒ¨åˆ†ä¸ºã€Œå­¦ä¹ ç‡ï¼ˆLearning rateï¼‰ã€ã€‚

æ€»ç»“ä¸€ä¸‹ï¼Œä»¥ä¸‹æ˜¯è®­ç»ƒè¿‡ç¨‹çš„æ­¥éª¤ï¼š

Training digits and labels => loss function => gradient (partial derivatives) => steepest descent => update weights and biases => repeat with next mini-batch of training images and labels

è®­ç»ƒæ•°å­—å’Œæ ‡ç­¾ => æŸå¤±å‡½æ•° => æ¢¯åº¦ï¼ˆéƒ¨åˆ†åå¯¼æ•°ï¼‰=> æœ€é™¡çš„æ¢¯åº¦ => æ›´æ–°æƒé‡å’Œåç½® => ä½¿ç”¨ä¸‹ä¸€ä¸ª mini-batch çš„å›¾åƒå’Œæ ‡ç­¾é‡å¤è¿™ä¸€è¿‡ç¨‹

ä¸ºä»€ä¹ˆä½¿ç”¨ 100 ä¸ªå›¾åƒå’Œæ ‡ç­¾çš„ mini-batchï¼Ÿ

ä½ å½“ç„¶ä¹Ÿå¯ä»¥åªåœ¨ä¸€ä¸ªç¤ºä¾‹å›¾åƒä¸­è®¡ç®—ä½ çš„æ¢¯åº¦å¹¶ä¸”ç«‹å³æ›´æ–°æƒé‡å’Œåç½®ï¼ˆè¿™åœ¨ç§‘å­¦æ–‡çŒ®ä¸­è¢«ç§°ä¸ºã€Œéšæœºæ¢¯åº¦ä¸‹é™ï¼ˆstochastic gradient descentï¼‰ã€ï¼‰ã€‚åœ¨ 100 ä¸ªæ ·æœ¬ä¸Šéƒ½è¿™æ ·åšå¯ä»¥å¾—åˆ°ä¸€ä¸ªæ›´å¥½åœ°è¡¨ç¤ºç”±ä¸åŒæ ·æœ¬å›¾åƒæ–½åŠ çº¦æŸçš„æ¢¯åº¦å¹¶ä¸”å¯èƒ½æ›´å¿«åœ°æœç€è§£å†³æ–¹æ¡ˆæ”¶æ•›ã€‚mini-batch çš„å¤§å°æ˜¯å¯è°ƒæ•´çš„å‚æ•°ã€‚è¿˜æœ‰ä¸€ä¸ªæ›´åŠ æŠ€æœ¯åŒ–çš„åŸå› ï¼šä½¿ç”¨æ‰¹å¤„ç†ä¹Ÿæ„å‘³ç€ä½¿ç”¨è¾ƒå¤§çš„çŸ©é˜µï¼Œè€Œè¿™äº›é€šå¸¸æ›´å®¹æ˜“åœ¨ GPU ä¸Šä¼˜åŒ–ã€‚

å¸¸è§é—®é¢˜

ä¸ºä»€ä¹ˆäº¤å‰ç†µæ˜¯åœ¨åˆ†ç±»é—®é¢˜ä¸­åˆé€‚çš„å®šä¹‰è·ç¦»ï¼Ÿ

ã€€ã€€è§£ç­”é“¾æ¥ï¼šhttps://jamesmccaffrey.wordpress.com/2013/11/05/why-you-should-use-cross-entropy-error-instead-of-classification-error-or-mean-squared-error-for-neural-network-classifier-training/

### å®éªŒï¼šè®©æˆ‘ä»¬æ¥çœ‹çœ‹ä»£ç 

å•å±‚ç¥ç»ç½‘ç»œçš„ä»£ç å·²ç»å†™å¥½äº†ã€‚è¯·æ‰“å¼€ mnist_1.0_softmax.py æ–‡ä»¶å¹¶æŒ‰è¯´æ˜è¿›è¡Œæ“ä½œã€‚

ä½ åœ¨æœ¬èŠ‚çš„ä»»åŠ¡æ˜¯ç†è§£å¼€å§‹ä»£ç ï¼Œä»¥ä¾¿ç¨åå¯¹å…¶æ”¹è¿›ã€‚

ä½ åº”è¯¥çœ‹åˆ°ï¼Œåœ¨æ–‡æ¡£ä¸­çš„è¯´æ˜å’Œå¯åŠ¨ä»£ç åªæœ‰å¾®å°çš„å·®åˆ«ã€‚å®ƒä»¬å¯¹åº”äºå¯è§†åŒ–çš„å‡½æ•°ï¼Œå¹¶ä¸”åœ¨æ³¨é‡Šä¸­è¢«æ ‡è®°ã€‚æ­¤å¤„å¯å¿½ç•¥ã€‚

ã€€ã€€mnist_1.0_softmax.pyï¼š

ã€€ã€€https://github.com/martin-gorner/tensorflow-mnist-tutorial/blob/master/mnist_1.0_softmax.py

ã€€ã€€![img](http://img.mp.itc.cn/upload/20170124/b8be8ddc1a9e41d19ddbffe3ed1ddc05_th.png)

ã€€ã€€æˆ‘ä»¬é¦–å…ˆå®šä¹‰ TensorFlow çš„å˜é‡å’Œå ä½ç¬¦ã€‚å˜é‡æ˜¯ä½ å¸Œæœ›è®­ç»ƒç®—æ³•ä¸ºä½ ç¡®å®šçš„æ‰€æœ‰çš„å‚æ•°ã€‚åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­å‚æ•°æ˜¯æƒé‡å’Œåå·®ã€‚

å ä½ç¬¦æ˜¯åœ¨è®­ç»ƒæœŸé—´å¡«å……å®é™…æ•°æ®çš„å‚æ•°ï¼Œé€šå¸¸æ˜¯è®­ç»ƒå›¾åƒã€‚æŒæœ‰è®­ç»ƒå›¾åƒçš„å¼ é‡çš„å½¢å¼æ˜¯ [None, 28, 28, 1]ï¼Œå…¶ä¸­çš„å‚æ•°ä»£è¡¨ï¼š

- 28, 28, 1: å›¾åƒæ˜¯ 28x28 æ¯åƒç´  x 1ï¼ˆç°åº¦ï¼‰ã€‚æœ€åä¸€ä¸ªæ•°å­—å¯¹äºå½©è‰²å›¾åƒæ˜¯ 3 ä½†åœ¨è¿™é‡Œå¹¶éæ˜¯å¿…é¡»çš„ã€‚
- None: è¿™æ˜¯ä»£è¡¨å›¾åƒåœ¨å°æ‰¹é‡ï¼ˆmini-batchï¼‰ä¸­çš„æ•°é‡ã€‚åœ¨è®­ç»ƒæ—¶å¯ä»¥å¾—åˆ°ã€‚

ã€€ã€€mnist_1.0_softmax.pyï¼š

ã€€ã€€https://github.com/martin-gorner/tensorflow-mnist-tutorial/blob/master/mnist_1.0_softmax.py

ã€€ã€€![img](http://img.mp.itc.cn/upload/20170124/71fef16bc66b4939975a236b58dac8ba_th.jpeg)

ã€€ã€€ç¬¬ä¸€è¡Œæ˜¯æˆ‘ä»¬å•å±‚ç¥ç»ç½‘ç»œçš„æ¨¡å‹ã€‚å…¬å¼æ˜¯æˆ‘ä»¬åœ¨å‰é¢çš„ç†è®ºéƒ¨åˆ†å»ºç«‹çš„ã€‚tf.reshape å‘½ä»¤å°†æˆ‘ä»¬çš„ 28Ã—28 çš„å›¾åƒè½¬åŒ–æˆ 784 ä¸ªåƒç´ çš„å•å‘é‡ã€‚åœ¨ reshape ä¸­çš„ã€Œ-1ã€æ„å‘³ç€ã€Œè®¡ç®—æœºï¼Œè®¡ç®—å‡ºæ¥ï¼Œè¿™åªæœ‰ä¸€ç§å¯èƒ½ã€ã€‚åœ¨å®é™…å½“ä¸­ï¼Œè¿™ä¼šæ˜¯å›¾åƒåœ¨å°æ‰¹æ¬¡ï¼ˆmini-batchï¼‰ä¸­çš„æ•°é‡ã€‚

ç„¶åï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªé¢å¤–çš„å ä½ç¬¦ç”¨äºè®­ç»ƒæ ‡ç­¾ï¼Œè¿™äº›æ ‡ç­¾ä¸è®­ç»ƒå›¾åƒä¸€èµ·è¢«æä¾›ã€‚

ç°åœ¨æˆ‘ä»¬æœ‰æ¨¡å‹é¢„æµ‹å’Œæ­£ç¡®çš„æ ‡ç­¾ï¼Œæ‰€ä»¥æˆ‘ä»¬è®¡ç®—äº¤å‰ç†µã€‚tf.reduce_sum æ˜¯å¯¹å‘é‡çš„æ‰€æœ‰å…ƒç´ æ±‚å’Œã€‚

æœ€åä¸¤è¡Œè®¡ç®—äº†æ­£ç¡®è¯†åˆ«æ•°å­—çš„ç™¾åˆ†æ¯”ã€‚è¿™æ˜¯ç•™ç»™è¯»è€…çš„ç†è§£ç»ƒä¹ ï¼Œä½¿ç”¨ TensorFlow API å‚è€ƒã€‚ä½ ä¹Ÿå¯ä»¥è·³è¿‡å®ƒä»¬ã€‚

ã€€ã€€mnist_1.0_softmax.pyï¼š

ã€€ã€€https://github.com/martin-gorner/tensorflow-mnist-tutorial/blob/master/mnist_1.0_softmax.py)

ã€€ã€€optimizer = tf.train.GradientDescentOptimizer(0.003)

ã€€ã€€train_step = optimizer.minimize(cross_entropy)

ã€€ã€€æ‰æ˜¯ TensorFlow å‘æŒ¥å®ƒåŠ›é‡çš„åœ°æ–¹ã€‚ä½ é€‰æ‹©ä¸€ä¸ªé€‚åº”å™¨ï¼ˆoptimiserï¼Œæœ‰è®¸å¤šå¯ä¾›é€‰æ‹©ï¼‰å¹¶ä¸”ç”¨å®ƒæœ€å°åŒ–äº¤å‰ç†µæŸå¤±ã€‚åœ¨è¿™ä¸€æ­¥ä¸­ï¼ŒTensorFlow è®¡ç®—ç›¸å¯¹äºæ‰€æœ‰æƒé‡å’Œæ‰€æœ‰åç½®ï¼ˆæ¢¯åº¦ï¼‰çš„æŸå¤±å‡½æ•°çš„åå¯¼æ•°ã€‚è¿™æ˜¯ä¸€ä¸ªå½¢å¼è¡ç”Ÿï¼ˆ formal derivationï¼‰ï¼Œå¹¶éæ˜¯ä¸€ä¸ªè€—æ—¶çš„æ•°å€¼å‹è¡ç”Ÿã€‚

æ¢¯åº¦ç„¶åè¢«ç”¨æ¥æ›´æ–°æƒé‡å’Œåç½®ã€‚å­¦ä¹ ç‡ä¸º 0.003ã€‚

æœ€åï¼Œæ˜¯æ—¶å€™æ¥è¿è¡Œè®­ç»ƒå¾ªç¯äº†ã€‚åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæ‰€æœ‰çš„ TensorFlow æŒ‡ä»¤éƒ½åœ¨å†…å­˜ä¸­å‡†å¤‡äº†ä¸€ä¸ªè®¡ç®—å›¾ï¼Œä½†æ˜¯è¿˜æœªè¿›è¡Œè®¡ç®—ã€‚

TensorFlow çš„ â€œå»¶è¿Ÿæ‰§è¡Œï¼ˆdeferred executionï¼‰â€ æ¨¡å‹ï¼šTensorFlow æ˜¯ä¸ºåˆ†å¸ƒå¼è®¡ç®—æ„å»ºçš„ã€‚å®ƒå¿…é¡»çŸ¥é“ä½ è¦è®¡ç®—çš„æ˜¯ä»€ä¹ˆã€ä½ çš„æ‰§è¡Œå›¾ï¼ˆexecution graphï¼‰ï¼Œç„¶åæ‰å¼€å§‹å‘é€è®¡ç®—ä»»åŠ¡åˆ°å„ç§è®¡ç®—æœºã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå®ƒæœ‰ä¸€ä¸ªå»¶è¿Ÿæ‰§è¡Œæ¨¡å‹ï¼Œä½ é¦–å…ˆä½¿ç”¨ TensorFlow å‡½æ•°åœ¨å†…å­˜ä¸­åˆ›é€ ä¸€ä¸ªè®¡ç®—å›¾ï¼Œç„¶åå¯åŠ¨ä¸€ä¸ªæ‰§è¡Œ Session å¹¶ä¸”ä½¿ç”¨ Session.run æ‰§è¡Œå®é™…è®¡ç®—ä»»åŠ¡ã€‚åœ¨æ­¤æ—¶ï¼Œå›¾å½¢æ— æ³•è¢«æ›´æ”¹ã€‚

ç”±äºè¿™ä¸ªæ¨¡å‹ï¼ŒTensorFlow æ¥ç®¡äº†åˆ†å¸ƒå¼è¿ç®—çš„å¤§é‡è¿ç­¹ã€‚ä¾‹å¦‚ï¼Œå‡å¦‚ä½ æŒ‡ç¤ºå®ƒåœ¨è®¡ç®—æœº 1 ä¸Šè¿è¡Œè®¡ç®—çš„ä¸€éƒ¨åˆ† ï¼Œè€Œåœ¨è®¡ç®—æœº 2 ä¸Šè¿è¡Œå¦ä¸€éƒ¨åˆ†ï¼Œå®ƒå¯ä»¥è‡ªåŠ¨è¿›è¡Œå¿…è¦çš„æ•°æ®ä¼ è¾“ã€‚

è®¡ç®—éœ€è¦å°†å®é™…æ•°æ®åé¦ˆè¿›ä½ åœ¨ TensorFlow ä»£ç ä¸­å®šä¹‰çš„å ä½ç¬¦ã€‚è¿™æ˜¯ä»¥ Python çš„ dictionary çš„å½¢å¼ç»™å‡ºçš„ï¼Œå…¶ä¸­çš„é”®æ˜¯å ä½ç¬¦çš„åç§°ã€‚

ã€€ã€€mnist_1.0_softmax.pyï¼š

ã€€ã€€https://github.com/martin-gorner/tensorflow-mnist-tutorial/blob/master/mnist_1.0_softmax.py

ã€€ã€€![img](http://img.mp.itc.cn/upload/20170124/a96dcaf397d342e18edb0ec24757f821.png)

ã€€ã€€åœ¨è¿™é‡Œæ‰§è¡Œçš„ train_step æ˜¯å½“æˆ‘ä»¬è¦æ±‚ TensorFlow æœ€å°åŒ–äº¤å‰ç†µæ—¶è·å¾—çš„ã€‚è¿™æ˜¯è®¡ç®—æ¢¯åº¦å’Œæ›´æ–°æƒé‡å’Œåç½®çš„æ­¥éª¤ã€‚

æœ€ç»ˆï¼Œæˆ‘ä»¬è¿˜éœ€è¦ä¸€äº›å€¼æ¥æ˜¾ç¤ºï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥è¿½è¸ªæˆ‘ä»¬æ¨¡å‹çš„æ€§èƒ½ã€‚

åœ¨è®­ç»ƒå›è·¯ä¸­ä½¿ç”¨è¯¥ä»£ç æ¥è®¡ç®—å‡†ç¡®åº¦å’Œäº¤å‰ç†µï¼ˆä¾‹å¦‚æ¯ 10 æ¬¡è¿­ä»£ï¼‰ï¼š

ã€€ã€€# success ?

ã€€ã€€a,c = sess.run([accuracy, cross_entropy], feed_dict=train_data)

é€šè¿‡åœ¨é¦ˆé€ dictionary ä¸­æä¾›æµ‹è¯•è€Œä¸æ˜¯è®­ç»ƒæ•°æ®ï¼Œå¯ä»¥å¯¹æµ‹è¯•æ•°æ®è¿›è¡ŒåŒæ ·çš„è®¡ç®—ï¼ˆä¾‹å¦‚æ¯ 100 æ¬¡è¿­ä»£è®¡ç®—ä¸€æ¬¡ã€‚æœ‰ 10,000 ä¸ªæµ‹è¯•æ•°å­—ï¼Œæ‰€ä»¥ä¼šè€—è´¹ CPU ä¸€äº›æ—¶é—´ï¼‰ï¼š

ã€€ã€€# success on test data ?

ã€€ã€€test_data={X: mnist.test.images, Y_: mnist.test.labels}

ã€€ã€€a,c = sess.run([accuracy, cross_entropy], feed=test_data)

TensorFlow å’Œ Numpy æ˜¯æœ‹å‹ï¼šåœ¨å‡†å¤‡è®¡ç®—å›¾æ—¶ï¼Œä½ åªéœ€è¦æ“çºµ TensorFlow å¼ é‡å’Œå‘½ä»¤ï¼Œæ¯”å¦‚ tf.matmul, tf.reshape ç­‰ã€‚

ç„¶è€Œï¼Œåªè¦æ‰§è¡Œ Session.run å‘½ä»¤ï¼Œå®ƒçš„è¿”å›å€¼å°±æ˜¯ Numpy å¼ é‡ï¼Œå³ Numpy å¯ä»¥ä½¿ç”¨çš„ numpy.ndarray å¯¹è±¡ä»¥åŠåŸºäºå®ƒçš„æ‰€æœ‰ç§‘å­¦è®¡ç®—åº“ã€‚è¿™å°±æ˜¯ä½¿ç”¨ matplotlibï¼ˆåŸºäº Numpy çš„æ ‡å‡† Python ç»˜å›¾åº“ï¼‰ä¸ºæœ¬å®éªŒæ„å»ºå®æ—¶å¯è§†åŒ–çš„æ–¹æ³•ã€‚

è¿™ä¸ªç®€å•çš„æ¨¡å‹å·²ç»èƒ½è¯†åˆ« 92% çš„æ•°å­—äº†ã€‚è¿™ä¸é”™ï¼Œä½†æ˜¯ä½ ç°åœ¨è¦æ˜¾è‘—åœ°æ”¹å–„å®ƒã€‚

ã€€ã€€![img](http://img.mp.itc.cn/upload/20170124/e65dd7cd3b2f43ab85279a8d39de470a_th.jpeg)

### å®éªŒ:å¢åŠ å±‚

ä¸ºäº†æé«˜è¯†åˆ«çš„å‡†ç¡®åº¦ï¼Œæˆ‘ä»¬å°†ä¸ºç¥ç»ç½‘ç»œå¢åŠ æ›´å¤šçš„å±‚ã€‚ç¬¬äºŒå±‚ç¥ç»å…ƒå°†è®¡ç®—å‰ä¸€å±‚ç¥ç»å…ƒè¾“å‡ºçš„åŠ æƒå’Œï¼Œè€Œéè®¡ç®—åƒç´ çš„åŠ æƒå’Œã€‚è¿™é‡Œæœ‰ä¸€ä¸ª 5 å±‚å…¨ç›¸è¿çš„ç¥ç»ç½‘ç»œçš„ä¾‹å­ï¼š

ã€€ã€€![img](http://img.mp.itc.cn/upload/20170124/1b4c2da0004c41988eb4bd83f28449dd_th.jpeg)

æˆ‘ä»¬ç»§ç»­ç”¨ softmax æ¥ä½œä¸ºæœ€åä¸€å±‚çš„æ¿€æ´»å‡½æ•°ï¼Œè¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆåœ¨åˆ†ç±»è¿™ä¸ªé—®é¢˜ä¸Šå®ƒæ€§èƒ½ä¼˜å¼‚çš„åŸå› ã€‚ä½†åœ¨ä¸­é—´å±‚ï¼Œæˆ‘ä»¬è¦ä½¿ç”¨æœ€ç»å…¸çš„æ¿€æ´»å‡½æ•°ï¼šsigmoidï¼šåœ¨è¿™ä¸€èŠ‚ä¸­ä½ çš„ä»»åŠ¡æ˜¯ä¸ºä½ çš„æ¨¡å‹å¢åŠ ä¸€åˆ°ä¸¤ä¸ªä¸­é—´å±‚ä»¥æé«˜å®ƒçš„æ€§èƒ½ã€‚

![img](http://img.mp.itc.cn/upload/20170124/6e069d408df443c49317ccd7784874b8_th.png)

ç­”æ¡ˆå¯ä»¥åœ¨ mnist_2.0_five_layers_sigmoid.py ä¸­æ‰¾åˆ°ã€‚åªæœ‰å½“ä½ å®åœ¨æƒ³ä¸å‡ºæ¥çš„æ—¶å€™å†ä½¿ç”¨å®ƒï¼ä¸ºäº†å¢åŠ ä¸€ä¸ªå±‚ï¼Œä½ éœ€è¦ä¸ºä¸­é—´å±‚å¢åŠ ä¸€ä¸ªé¢å¤–çš„æƒé‡çŸ©é˜µå’Œä¸€ä¸ªé¢å¤–çš„åç½®å‘é‡ï¼š

ã€€ã€€W1 = tf.Variable(tf.truncated_normal([28*28, 200] ,stddev=0.1))

ã€€ã€€B1 = tf.Variable(tf.zeros([200]))

ã€€ã€€W2 = tf.Variable(tf.truncated_normal([200, 10], stddev=0.1))

ã€€ã€€B2 = tf.Variable(tf.zeros([10]))

å¯¹ï¼Œå°±è¿™ä¹ˆåšã€‚é€šè¿‡ 2 ä¸ªä¸­é—´å±‚ä»¥åŠä¾‹å­ä¸­ 200 ä¸ªå’Œ 100 ä¸ªç¥ç»å…ƒï¼Œä½ ç°åœ¨åº”è¯¥èƒ½å¤ŸæŠŠä½ çš„ç¥ç»ç½‘ç»œçš„å‡†ç¡®åº¦æ¨é«˜åˆ° 97% äº†ã€‚

![img](http://img.mp.itc.cn/upload/20170124/e60d8b29dad048fa8e5917c95c7a6153_th.jpeg)

### å®éªŒï¼šæ·±åº¦ç½‘ç»œéœ€è¦ç‰¹åˆ«æ³¨æ„çš„åœ°æ–¹

éšç€å±‚æ•°çš„å¢åŠ ï¼Œç¥ç»ç½‘ç»œè¶Šæ¥è¶Šéš¾ä»¥æ”¶æ•›ã€‚ä½†ç°åœ¨æˆ‘ä»¬çŸ¥é“å¦‚ä½•æ§åˆ¶å®ƒä»¬çš„è¡Œä¸ºäº†ã€‚è¿™é‡Œæ˜¯ä¸€äº›åªç”¨ 1 è¡Œå°±å¯ä»¥å®ç°çš„æ”¹è¿›ï¼Œå½“ä½ çœ‹åˆ°å‡†ç¡®åº¦æ›²çº¿å‡ºç°å¦‚ä¸‹æƒ…å†µçš„æ—¶å€™ï¼Œè¿™äº›å°æŠ€å·§ä¼šå¸®åˆ°ä½ ï¼š

![img](http://img.mp.itc.cn/upload/20170124/5b31861eff624a32bca2e5c29169a7c1_th.png)

ä¿®æ­£çº¿æ€§å•å…ƒï¼ˆReLUï¼‰æ¿€æ´»å‡½æ•°

åœ¨æ·±åº¦ç½‘ç»œé‡Œï¼Œsigmoid æ¿€æ´»å‡½æ•°ç¡®å®èƒ½å¸¦æ¥å¾ˆå¤šé—®é¢˜ã€‚å®ƒæŠŠæ‰€æœ‰çš„å€¼éƒ½æŒ¤åˆ°äº† 0 åˆ° 1 ä¹‹é—´ï¼Œè€Œä¸”å½“ä½ é‡å¤åšçš„æ—¶å€™ï¼Œç¥ç»å…ƒçš„è¾“å‡ºå’Œå®ƒä»¬çš„æ¢¯åº¦éƒ½å½’é›¶äº†ã€‚å€¼å¾—ä¸€æçš„æ˜¯ï¼Œå‡ºäºå†å²åŸå› ï¼Œä¸€äº›ç°ä»£ç¥ç»ç½‘ç»œä½¿ç”¨äº† ReLUï¼ˆä¿®æ­£çº¿æ€§å•å…ƒï¼‰ï¼Œå®ƒå¤§è‡´æ˜¯å¦‚ä¸‹è¿™ä¸ªæ ·å­ï¼š

![img](http://img.mp.itc.cn/upload/20170124/a06abc6c13f743c28dd4b28018854629.png)

å‡çº§ 1/4ï¼šç”¨ RELU æ›¿æ¢ä½ æ‰€æœ‰çš„ sigmoidï¼Œç„¶åä½ ä¼šå¾—åˆ°ä¸€ä¸ªæ›´å¿«çš„åˆå§‹æ”¶æ•›å¹¶ä¸”å½“æˆ‘ä»¬ç»§ç»­å¢åŠ å±‚çš„æ—¶å€™ä¹Ÿé¿å…äº†ä¸€äº›åç»­é—®é¢˜çš„äº§ç”Ÿã€‚ä»…ä»…åœ¨ä»£ç ä¸­ç®€å•åœ°ç”¨ tf.nn.relu æ¥æ›¿æ¢ tf.nn.sigmoid å°±å¯ä»¥äº†ã€‚

ä¸€ä¸ªæ›´å¥½çš„ä¼˜åŒ–å™¨

åœ¨ä¸€ä¸ªç‰¹åˆ«å¤šç»´çš„ç©ºé—´é‡Œï¼Œå°±åƒå½“å‰è¿™ä¸ªæƒ…å†µâ€”â€”æˆ‘ä»¬æœ‰ 10K é‡çº§çš„æƒå€¼å’Œåç½®å€¼â€”â€”ã€Œéç‚¹ (saddle pointsï¼‰ã€ä¼šé¢‘ç¹å‡ºç°ã€‚è¿™äº›ç‚¹ä¸æ˜¯å±€éƒ¨æœ€å°å€¼ç‚¹ï¼Œä½†å®ƒçš„æ¢¯åº¦å´æ˜¯é›¶ï¼Œé‚£ä¹ˆæ¢¯åº¦é™çš„ä¼˜åŒ–ä¼šå¡åœ¨è¿™é‡Œã€‚TensorFlow æœ‰ä¸€ç³»åˆ—å¯ä»¥ç”¨çš„ä¼˜åŒ–å™¨ï¼ŒåŒ…æ‹¬ä¸€äº›å¸¦æœ‰ä¸€å®šçš„æƒ¯æ€§ï¼Œèƒ½å¤Ÿå®‰å…¨è¶Šè¿‡éç‚¹çš„ä¼˜åŒ–å™¨ã€‚

å‡çº§ 2/4ï¼šç°åœ¨å°†ä½ çš„ tf.train.GradientDescentOptimiser æ›¿æ¢ä¸º tf.train.AdamOptimizerã€‚

éšæœºåˆå§‹åŒ–

å‡†ç¡®æ€§ä¸€ç›´å¡åœ¨ 0.1ï¼Ÿä½ æŠŠä½ çš„æƒå€¼åˆå§‹åŒ–æˆéšæœºå€¼äº†æ²¡ï¼Ÿå¯¹äºåç½®å€¼ï¼Œå¦‚æœç”¨ ReLU çš„è¯ï¼Œæœ€å¥½çš„åŠæ³•å°±æ˜¯æŠŠå®ƒä»¬éƒ½åˆå§‹åŒ–æˆå°çš„æ­£å€¼ï¼Œè¿™æ ·ç¥ç»å…ƒä¸€å¼€å§‹å°±ä¼šå·¥ä½œåœ¨ ReLU çš„éé›¶åŒºåŸŸå†…ã€‚

ã€€ã€€W = tf.Variable(tf.truncated_normal([K, L] ,stddev=0.1))

ã€€ã€€B = tf.Variable(tf.ones([L])/10)

å‡çº§ 3/4ï¼šç°åœ¨æ£€æŸ¥æ˜¯å¦ä½ æ‰€æœ‰çš„æƒå€¼å’Œåç½®å€¼éƒ½è¢«åˆå§‹åŒ–å¥½äº†ã€‚ä¸Šå›¾æ‰€ç¤ºçš„ 0.1 ä¼šä½œä¸ºåç½®å€¼ã€‚

ä¸å®šå€¼ï¼ˆNaNï¼‰

![img](http://img.mp.itc.cn/upload/20170124/18bf142ee7894aa18c015ddba8c645ab_th.jpeg)

å¦‚æœä½ çœ‹åˆ°ä½ çš„ç²¾ç¡®æ›²çº¿é™¡ç„¶ä¸‹æ»‘å¹¶ä¸”è°ƒè¯•å£è¾“å‡ºçš„äº¤å‰ç†µæ˜¯ NaNï¼Œä¸ç”¨æ„Ÿåˆ°å¤´ç–¼ï¼Œä½ å…¶å®æ˜¯æ­£åœ¨å°è¯•è®¡ç®— log(0)ï¼Œè€Œè¿™è‚¯å®šæ˜¯ä¸ªä¸å®šå€¼ï¼ˆNaNï¼‰ã€‚è¿˜è®°å¾—å—ï¼Œäº¤å‰ç†µçš„è®¡ç®—æ¶‰åŠåˆ°å¯¹ softmax å±‚çš„è¾“å‡ºå–å¯¹æ•°ã€‚é‰´äº softmax åŸºæœ¬ä¸Šæ˜¯ä¸€ä¸ªæŒ‡æ•°ï¼Œå®ƒè‚¯å®šä¸æ˜¯ 0ï¼Œæˆ‘ä»¬å¦‚æœç”¨ 32 ä½ç²¾åº¦çš„æµ®ç‚¹è¿ç®—å°±è¿˜å¥½ï¼Œexp(-100) åŸºæœ¬ä¸Šå¯ä»¥ç®—ä½œæ˜¯ 0 äº†ã€‚

å¾ˆå¹¸è¿ï¼ŒTensorFlow æœ‰ä¸€ä¸ªéå¸¸æ–¹ä¾¿çš„å‡½æ•°å¯ä»¥åœ¨å•æ­¥å†…è®¡ç®— softmax å’Œäº¤å‰ç†µï¼Œå®ƒæ˜¯ä»¥ä¸€ç§æ•°å€¼ä¸Šè¾ƒä¸ºç¨³å®šçš„æ–¹å¼å®ç°çš„ã€‚å¦‚æœè¦ä½¿ç”¨å®ƒï¼Œä½ éœ€è¦åœ¨åº”ç”¨ softmax ä¹‹å‰å°†åŸå§‹çš„æƒé‡å’ŒåŠ ä¸Šä½ æœ€åä¸€å±‚çš„åç½®éš”ç¦»å¼€æ¥ï¼ˆåœ¨ç¥ç»ç½‘ç»œçš„æœ¯è¯­é‡Œå«ã€Œlogitsã€ï¼‰ã€‚

ã€€ã€€å¦‚æœä½ æ¨¡å‹çš„æœ€åä¸€è¡Œæ˜¯è¿™æ ·çš„ï¼š

ã€€ã€€Y = tf.nn.softmax(tf.matmul(Y4, W5) + B5)

ã€€ã€€ä½ éœ€è¦æŠŠå®ƒæ›¿æ¢æˆï¼š

ã€€ã€€Ylogits = tf.matmul(Y4, W5) + B5Y = tf.nn.softmax(Ylogits)

ã€€ã€€å¹¶ä¸”ä½ ç°åœ¨èƒ½ä»¥ä¸€ç§å®‰å…¨çš„æ–¹å¼è®¡ç®—äº¤å‰ç†µäº†ï¼š

ã€€ã€€cross_entropy = tf.nn.softmax_cross_entropy_with_logits(Ylogits, Y_)

åŒæ ·åŠ ä¸Šä¸‹é¢è¿™è¡Œä»£ç ä½¿å¾—æµ‹è¯•å’Œè®­ç»ƒçš„äº¤å‰ç†µèƒ½å¤ŸåŒæ¡†æ˜¾ç¤ºï¼š

ã€€ã€€cross_entropy = tf.reduce_mean(cross_entropy)*100

å‡çº§ 4/4ï¼šè¯·æŠŠ tf.nn.softmax_cross_entropy_with_logits åŠ åˆ°ä½ çš„ä»£ç é‡Œã€‚ä½ ä¹Ÿå¯ä»¥è·³è¿‡è¿™ä¸€æ­¥ï¼Œç­‰ä½ çœŸåœ¨ä½ çš„è¾“å‡ºé‡Œçœ‹åˆ° NaN ä»¥åå†æ¥åšè¿™æ­¥ã€‚ç°åœ¨ï¼Œä½ å·²ç»å‡†å¤‡å¥½å®ç°ã€Œæ·±åº¦ã€äº†ã€‚

### å®éªŒï¼šå­¦ä¹ é€Ÿç‡è¡°é€€

é€šè¿‡ä¸¤ä¸ªã€ä¸‰ä¸ªæˆ–è€…å››ä¸ªä¸­é—´å±‚ï¼Œä½ ç°åœ¨å¯ä»¥å°†å‡†ç¡®åº¦æå‡è‡³æ¥è¿‘ 98%ï¼Œå½“ç„¶ï¼Œä½ çš„è¿­ä»£æ¬¡æ•°è¦è¾¾åˆ° 5000 æ¬¡ä»¥ä¸Šã€‚ä¸è¿‡ä½ ä¼šå‘ç°ä½ å¹¶ä¸æ€»æ˜¯ä¼šå¾—åˆ°è¿™æ ·çš„ç»“æœã€‚

ã€€ã€€![img](http://img.mp.itc.cn/upload/20170124/a4492d6cbbb343aab07a355246c915de_th.jpeg)

è¿™äº›æ›²çº¿å¾ˆå˜ˆæ‚ï¼Œçœ‹çœ‹æµ‹è¯•ç²¾ç¡®åº¦å§ï¼šå®ƒåœ¨å…¨ç™¾åˆ†æ¯”èŒƒå›´å†…è·³ä¸Šè·³ä¸‹ã€‚è¿™æ„å‘³ç€å³ä½¿ 0.003 çš„å­¦ä¹ ç‡æˆ‘ä»¬è¿˜æ˜¯å¤ªå¿«äº†ã€‚ä½†æˆ‘ä»¬ä¸èƒ½ä»…ä»…å°†å­¦ä¹ ç‡é™¤ä»¥åæˆ–è€…æ°¸è¿œä¸åœåœ°åšè®­ç»ƒã€‚ä¸€ä¸ªå¥½çš„è§£å†³æ–¹æ¡ˆæ˜¯å¼€å§‹å¾ˆå¿«éšåå°†å­¦ä¹ é€Ÿç‡æŒ‡æ•°çº§è¡°å‡è‡³æ¯”å¦‚è¯´ 0.0001ã€‚

è¿™ä¸ªå°æ”¹å˜çš„å½±å“æ˜¯æƒŠäººçš„ã€‚ä½ ä¼šçœ‹åˆ°å¤§éƒ¨åˆ†çš„å™ªå£°æ¶ˆå¤±äº†å¹¶ä¸”æµ‹è¯•ç²¾ç¡®åº¦æŒç»­ç¨³å®šåœ¨ 98% ä»¥ä¸Šã€‚

![img](http://img.mp.itc.cn/upload/20170124/41294f08d52d4959bb4b01c8e925f056_th.jpeg)

å†çœ‹çœ‹è®­ç»ƒç²¾ç¡®åº¦æ›²çº¿ã€‚åœ¨å¥½å¤šä¸ª epoch é‡Œéƒ½è¾¾åˆ°äº† 100%ï¼ˆä¸€ä¸ª epoch=500 æ¬¡è¿­ä»£=å…¨éƒ¨è®­ç»ƒå›¾ç‰‡è®­ç»ƒä¸€æ¬¡ï¼‰ã€‚ç¬¬ä¸€æ¬¡æˆ‘ä»¬èƒ½å¾ˆå¥½åœ°è¯†åˆ«è®­ç»ƒå›¾ç‰‡äº†ã€‚

è¯·æŠŠå­¦ä¹ ç‡è¡°é€€åŠ åˆ°ä½ çš„ä»£ç é‡Œã€‚ä¸ºäº†æŠŠä¸€ä¸ªä¸åŒçš„å­¦ä¹ ç‡åœ¨æ¯æ¬¡è¿­ä»£æ—¶ä¼ ç»™ AdamOptimizerï¼Œä½ éœ€è¦å®šä¹‰ä¸€ä¸ªæ–°çš„å ä½ç¬¦ï¼ˆplaceholderï¼‰å¹¶åœ¨æ¯æ¬¡è¿­ä»£æ—¶é€šè¿‡ feed_dict èµ‹ç»™å®ƒä¸€ä¸ªæ–°çš„å‚æ•°ã€‚

è¿™é‡Œæ˜¯ä¸€ä¸ªæŒ‡æ•°çº§è¡°å‡çš„æ–¹ç¨‹ï¼šlr = lrmin+(lrmax-lrmin)*exp(-i/2000) ç­”æ¡ˆå¯ä»¥åœ¨è¿™ä¸ªæ–‡ä»¶é‡Œæ‰¾åˆ°ï¼šmnist_2.1_five_layers_relu_lrdecay.pyã€‚å¦‚æœä½ è¢«å¡ä½äº†å¯ä»¥ç”¨å®ƒã€‚

![img](http://img.mp.itc.cn/upload/20170124/260e6a3277984432adc3e945251e5f18_th.jpeg)

### å®éªŒï¼šdropoutã€è¿‡æ‹Ÿåˆ

ä½ å¯èƒ½å·²ç»æ³¨æ„åˆ°åœ¨æ•°åƒæ¬¡è¿­ä»£ä¹‹åï¼Œæµ‹è¯•å’Œè®­ç»ƒæ•°æ®çš„äº¤å‰ç†µæ›²çº¿å¼€å§‹ä¸ç›¸è¿ã€‚å­¦ä¹ ç®—æ³•åªæ˜¯åœ¨è®­ç»ƒæ•°æ®ä¸Šåšå·¥ä½œå¹¶ç›¸åº”åœ°ä¼˜åŒ–è®­ç»ƒçš„äº¤å‰ç†µã€‚å®ƒå†ä¹Ÿçœ‹ä¸åˆ°æµ‹è¯•æ•°æ®äº†ï¼Œæ‰€ä»¥è¿™ä¸€ç‚¹ä¹Ÿä¸å¥‡æ€ªï¼šè¿‡äº†ä¸€ä¼šå„¿å®ƒçš„å·¥ä½œä¸å†å¯¹æµ‹è¯•äº¤å‰ç†µäº§ç”Ÿä»»ä½•å½±å“ï¼Œäº¤å‰ç†µåœæ­¢äº†ä¸‹é™ï¼Œæœ‰æ—¶ç”šè‡³åå¼¹å›æ¥ã€‚

ã€€ã€€![img](http://img.mp.itc.cn/upload/20170124/2b215ed2c1984612bdba47bf0dba1188_th.jpeg)

å®ƒä¸ä¼šç«‹åˆ»å½±å“ä½ æ¨¡å‹å¯¹äºçœŸå®ä¸–ç•Œçš„è¯†åˆ«èƒ½åŠ›ï¼Œä½†æ˜¯å®ƒä¼šä½¿ä½ è¿è¡Œçš„ä¼—å¤šè¿­ä»£æ¯«æ— ç”¨å¤„ï¼Œè€Œä¸”è¿™åŸºæœ¬ä¸Šæ˜¯ä¸€ä¸ªä¿¡å·â€”â€”å‘Šè¯‰æˆ‘ä»¬è®­ç»ƒå·²ç»ä¸èƒ½å†ä¸ºæ¨¡å‹æä¾›è¿›ä¸€æ­¥æ”¹è¿›äº†ã€‚è¿™ç§æ— æ³•è¿æ¥é€šå¸¸ä¼šè¢«æ ‡æ˜ã€Œè¿‡æ‹Ÿåˆï¼ˆoverfittingï¼‰ã€ï¼Œè€Œä¸”å½“ä½ çœ‹åˆ°è¿™ä¸ªçš„æ—¶å€™ï¼Œä½ å¯ä»¥å°è¯•é‡‡ç”¨ä¸€ç§è§„èŒƒåŒ–ï¼ˆregularizationï¼‰æŠ€æœ¯ï¼Œç§°ä¹‹ä¸ºã€Œdropoutã€ã€‚

ã€€ã€€![img](http://img.mp.itc.cn/upload/20170124/8ba81eadbd6f4383a4af3a8dc13bbe53_th.jpeg)

åœ¨ dropout é‡Œï¼Œåœ¨æ¯ä¸€æ¬¡è®­ç»ƒè¿­ä»£çš„æ—¶å€™ï¼Œä½ å¯ä»¥ä»ç½‘ç»œä¸­éšæœºåœ°æ”¾å¼ƒä¸€äº›ç¥ç»å…ƒã€‚ä½ å¯ä»¥é€‰æ‹©ä¸€ä¸ªä½¿ç¥ç»å…ƒç»§ç»­ä¿ç•™çš„æ¦‚ç‡ pkeepï¼Œé€šå¸¸æ˜¯ 50% åˆ° 75% ä¹‹é—´ï¼Œç„¶ååœ¨æ¯ä¸€æ¬¡è®­ç»ƒçš„è¿­ä»£æ—¶ï¼Œéšæœºåœ°æŠŠä¸€äº›ç¥ç»å…ƒè¿åŒå®ƒä»¬çš„æƒé‡å’Œåç½®ä¸€èµ·å»æ‰ã€‚åœ¨ä¸€æ¬¡è¿­ä»£é‡Œï¼Œä¸åŒçš„ç¥ç»å…ƒå¯ä»¥è¢«ä¸€èµ·å»æ‰ï¼ˆè€Œä¸”ä½ ä¹ŸåŒæ ·éœ€è¦ç­‰æ¯”ä¾‹åœ°ä¿ƒè¿›å‰©ä½™ç¥ç»å…ƒçš„è¾“å‡ºï¼Œä»¥ç¡®ä¿ä¸‹ä¸€å±‚çš„æ¿€æ´»ä¸ä¼šç§»åŠ¨ï¼‰ã€‚å½“æµ‹è¯•ä½ ç¥ç»ç½‘ç»œæ€§èƒ½çš„æ—¶å€™ï¼Œä½ å†æŠŠæ‰€æœ‰çš„ç¥ç»å…ƒéƒ½è£…å›æ¥ (pkeep=1)ã€‚

TensorFlow æä¾›ä¸€ä¸ª dropout å‡½æ•°å¯ä»¥ç”¨åœ¨ä¸€å±‚ç¥ç»ç½‘ç»œçš„è¾“å‡ºä¸Šã€‚å®ƒéšæœºåœ°æ¸…é›¶ä¸€äº›è¾“å‡ºå¹¶ä¸”æŠŠå‰©ä¸‹çš„æå‡ 1/pkeepã€‚è¿™é‡Œæ˜¯å¦‚ä½•æŠŠå®ƒç”¨åœ¨ä¸€ä¸ªä¸¤å±‚ç¥ç»ç½‘ç»œä¸Šçš„ä¾‹å­ã€‚

ã€€ã€€# feed in 1 when testing, 0.75 when training

ã€€ã€€pkeep = tf.placeholder(tf.float32)

ã€€ã€€Y1 = tf.nn.relu(tf.matmul(X, W1) + B1)

ã€€ã€€Y1d = tf.nn.dropout(Y1, pkeep)

ã€€ã€€Y = tf.nn.softmax(tf.matmul(Y1d, W2) + B2)

ä½ ç°åœ¨å¯ä»¥åœ¨ç½‘ç»œä¸­æ¯ä¸ªä¸­é—´å±‚ä»¥åæ’å…¥ dropoutã€‚å¦‚æœä½ æ²¡æ—¶é—´æ·±å…¥é˜…è¯»çš„è¯ï¼Œè¿™æ˜¯æœ¬é¡¹ç›®é‡Œçš„å¯é€‰æ­¥éª¤ã€‚

è¯¥è§£å†³æ–¹æ¡ˆå¯ä»¥åœ¨ [mnist_2.2_five_layers_relu_lrdecay_dropout.py](https://github.com/martin-gorner/tensorflow-mnist-tutorial/blob/master/mnist_2.2_five_layers_relu_lrdecay_dropout.py)é‡Œæ‰¾åˆ°ã€‚å¦‚æœä½ è¢«éš¾ä½äº†ï¼Œå¯ä»¥ç”¨å®ƒã€‚

![img](http://img.mp.itc.cn/upload/20170124/59419fef6dbd401aa484dfb9983712f7_th.jpeg)

ä½ ä¼šçœ‹åˆ°æµ‹è¯•æŸå¤±å·²ç»è¢«æå›æ¥äº†ï¼Œå·²ç»åœ¨å¯æ§èŒƒå›´å†…äº†ï¼Œä¸è¿‡è‡³å°‘åœ¨è¿™ä¸ªä¾‹å­ä¸­å™ªå£°é‡æ–°å‡ºç°äº†ï¼ˆå¦‚æœä½ çŸ¥é“ dropout çš„å·¥ä½œåŸç†çš„è¯ï¼Œè¿™ä¸€ç‚¹ä¹Ÿä¸å¥‡æ€ªï¼‰ã€‚æµ‹è¯•çš„å‡†ç¡®åº¦ä¾ç„¶æ²¡å˜ï¼Œè¿™å€’æ˜¯æœ‰ç‚¹å°å¤±æœ›ã€‚è¿™ä¸ªã€Œè¿‡æ‹Ÿåˆã€ä¸€å®šè¿˜æœ‰å…¶å®ƒåŸå› ã€‚åœ¨æˆ‘ä»¬ç»§ç»­è¿›è¡Œä¸‹ä¸€æ­¥ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆæ‰¼è¦é‡è¿°ä¸€ä¸‹æˆ‘ä»¬åˆ°ç›®å‰ä¸ºæ­¢ç”¨è¿‡çš„æ‰€æœ‰å·¥å…·ï¼š

![img](http://img.mp.itc.cn/upload/20170124/cfcb109bbbe040d29e61d02d78059124_th.jpeg)

æ— è®ºæˆ‘ä»¬åšä»€ä¹ˆï¼Œæˆ‘ä»¬çœ‹ä¸Šå»éƒ½ä¸å¯èƒ½å¾ˆæ˜¾è‘—åœ°è§£å†³ 98% çš„éšœç¢ï¼Œè€Œä¸”æˆ‘ä»¬çš„æŸå¤±æ›²çº¿ä¾ç„¶æ˜¾ç¤ºã€Œè¿‡æ‹Ÿåˆã€æ— æ³•è¿æ¥ã€‚ä»€ä¹ˆæ˜¯çœŸæ­£çš„ã€Œè¿‡æ‹Ÿåˆã€ï¼Ÿè¿‡æ‹Ÿåˆå‘ç”Ÿåœ¨è¯¥ç¥ç»ç½‘ç»œå­¦å¾—ã€Œä¸å¥½ã€çš„æ—¶å€™ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹è¯¥ç¥ç»ç½‘ç»œå¯¹äºè®­ç»ƒæ ·æœ¬åšå¾—å¾ˆå¥½ï¼Œå¯¹çœŸå®åœºæ™¯å´å¹¶ä¸æ˜¯å¾ˆå¥½ã€‚æœ‰ä¸€äº›åƒ dropout ä¸€æ ·çš„è§„èŒƒåŒ–æŠ€æœ¯èƒ½å¤Ÿè¿«ä½¿å®ƒå­¦ä¹ å¾—æ›´å¥½ï¼Œä¸è¿‡è¿‡æ‹Ÿåˆè¿˜æœ‰æ›´æ·±å±‚çš„åŸå› ã€‚

åŸºæœ¬çš„è¿‡æ‹Ÿåˆå‘ç”Ÿåœ¨ä¸€ä¸ªç¥ç»ç½‘ç»œé’ˆå¯¹æ‰‹å¤´çš„é—®é¢˜æœ‰å¤ªå¤šçš„è‡ªç”±åº¦çš„æ—¶å€™ã€‚æƒ³è±¡ä¸€ä¸‹æˆ‘ä»¬æœ‰å¦‚æ­¤å¤šçš„ç¥ç»å…ƒä»¥è‡³äºæ‰€ç»„æˆçš„ç½‘ç»œå¯ä»¥å­˜å‚¨æˆ‘ä»¬æ‰€æœ‰çš„è®­ç»ƒå›¾åƒå¹¶ä¾é ç‰¹å¾åŒ¹é…æ¥è¯†åˆ«å®ƒä»¬ã€‚å®ƒä¼šåœ¨çœŸå®ä¸–ç•Œçš„æ•°æ®é‡Œè¿·å¤±ã€‚ä¸€ä¸ªç¥ç»ç½‘ç»œå¿…é¡»æœ‰æŸç§ç¨‹åº¦ä¸Šçš„çº¦æŸä»¥ä½¿å®ƒèƒ½å¤Ÿå½’çº³æ¨ç†å®ƒåœ¨å­¦ä¹ ä¸­æ‰€å­¦åˆ°çš„ä¸œè¥¿ã€‚

å¦‚æœä½ åªæœ‰å¾ˆå°‘çš„è®­ç»ƒæ•°æ®ï¼Œç”šè‡³ä¸€ä¸ªå¾ˆå°çš„ç½‘ç»œéƒ½èƒ½å¤Ÿç”¨å¿ƒå­¦ä¹ å®ƒã€‚ä¸€èˆ¬æ¥è¯´ï¼Œä½ æ€»æ˜¯éœ€è¦å¾ˆå¤šæ•°æ®æ¥è®­ç»ƒç¥ç»ç½‘ç»œã€‚

æœ€åï¼Œå¦‚æœä½ å·²ç»åšå®Œäº†æ‰€æœ‰çš„æ­¥éª¤ï¼ŒåŒ…æ‹¬å®éªŒäº†ä¸åŒå¤§å°çš„ç½‘ç»œä»¥ç¡®ä¿å®ƒçš„è‡ªç”±åº¦å·²ç»çº¦æŸå¥½äº†ã€é‡‡ç”¨äº† dropoutã€å¹¶ä¸”è®­ç»ƒäº†å¤§é‡çš„æ•°æ®ï¼Œä½ å¯èƒ½ä¼šå‘ç°ä½ è¿˜æ˜¯è¢«å¡åœ¨äº†å½“å‰çš„æ€§èƒ½å±‚æ¬¡ä¸Šå†ä¹Ÿä¸Šä¸å»äº†ã€‚è¿™è¯´æ˜ä½ çš„ç¥ç»ç½‘ç»œåœ¨å®ƒå½“å‰çš„å½¢æ€ä¸‹å·²ç»æ— æ³•ä»ä½ æä¾›çš„æ•°æ®ä¸­æŠ½å–åˆ°æ›´å¤šçš„ä¿¡æ¯äº†ï¼Œå°±åƒæˆ‘ä»¬è¿™ä¸ªä¾‹å­è¿™æ ·ã€‚

è¿˜è®°å¾—æˆ‘ä»¬å¦‚ä½•ä½¿ç”¨æˆ‘ä»¬çš„å›¾åƒå—ï¼Ÿæ˜¯æ‰€æœ‰çš„åƒç´ éƒ½å±•å¹³åˆ°ä¸€ä¸ªå‘é‡é‡Œä¹ˆï¼Ÿè¿™æ˜¯ä¸€ä¸ªå¾ˆç³Ÿç³•çš„æƒ³æ³•ã€‚æ‰‹å†™çš„æ•°å­—æ˜¯ç”±ä¸€ä¸ªä¸ªå½¢çŠ¶ç»„æˆçš„ï¼Œå½“æˆ‘ä»¬æŠŠåƒç´ å±•å¹³åæˆ‘ä»¬ä¼šä¸¢æ‰è¿™äº›å½¢çŠ¶ä¿¡æ¯ã€‚ä¸è¿‡ï¼Œæœ‰ä¸€ç§ç¥ç»ç½‘ç»œå¯ä»¥åˆ©ç”¨è¿™äº›å½¢çŠ¶ä¿¡æ¯ï¼šå·ç§¯ç½‘ç»œï¼ˆconvolutional networkï¼‰ã€‚è®©æˆ‘ä»¬æ¥è¯•è¯•ã€‚

### ç†è®ºï¼šå·ç§¯ç½‘ç»œ

ã€€ã€€![img](http://img.mp.itc.cn/upload/20170124/0eb4bf030ecc488a8d2f990c11e7272c_th.jpeg)

åœ¨å·ç§¯ç½‘ç»œå±‚ä¸­ï¼Œä¸€ä¸ªã€Œç¥ç»å…ƒã€ä»…å¯¹è¯¥å›¾åƒä¸Šçš„ä¸€ä¸ªå°éƒ¨åˆ†çš„åƒç´ æ±‚åŠ æƒå’Œã€‚ç„¶åï¼Œå®ƒé€šå¸¸ä¼šæ·»åŠ ä¸€ä¸ªåç½®å•å…ƒï¼Œå¹¶ä¸”å°†å¾—åˆ°çš„åŠ æƒå’Œä¼ é€’ç»™æ¿€æ´»å‡½æ•°ã€‚ä¸å…¨è¿æ¥ç½‘ç»œç›¸æ¯”ï¼Œå…¶æœ€å¤§çš„åŒºåˆ«åœ¨äºå·ç§¯ç½‘ç»œçš„æ¯ä¸ªç¥ç»å…ƒé‡å¤ä½¿ç”¨ç›¸åŒçš„æƒé‡ï¼Œè€Œä¸æ˜¯æ¯ä¸ªç¥ç»å…ƒéƒ½æœ‰è‡ªå·±çš„æƒé‡ã€‚

åœ¨ä¸Šé¢çš„åŠ¨ç”»ä¸­ï¼Œä½ å¯ä»¥çœ‹åˆ°é€šè¿‡è¿ç»­ä¿®æ”¹å›¾ç‰‡ä¸Šä¸¤ä¸ªæ–¹å‘çš„æƒé‡ï¼ˆå·ç§¯ï¼‰ï¼Œèƒ½å¤Ÿè·å¾—ä¸å›¾ç‰‡ä¸Šçš„åƒç´ ç‚¹æ•°é‡ç›¸åŒçš„è¾“å‡ºå€¼ï¼ˆå°½ç®¡åœ¨è¾¹ç¼˜å¤„éœ€è¦å¡«å……ï¼ˆpaddingï¼‰ï¼‰ã€‚

è¦äº§ç”Ÿä¸€ä¸ªè¾“å‡ºå€¼å¹³é¢ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä¸€å¼  4x4 å¤§å°çš„å½©è‰²å›¾ç‰‡ä½œä¸ºå‡ºè¾“å…¥ã€‚åœ¨è¿™ä¸ªåŠ¨ç”»å½“ä¸­ï¼Œæˆ‘ä»¬éœ€è¦ 4x4x3=48 ä¸ªæƒé‡ï¼Œè¿™è¿˜ä¸å¤Ÿï¼Œä¸ºäº†å¢åŠ æ›´å¤šè‡ªç”±åº¦ï¼Œæˆ‘ä»¬è¿˜éœ€è¦é€‰å–ä¸åŒç»„çš„æƒé‡å€¼é‡å¤å®éªŒã€‚

![img](http://img.mp.itc.cn/upload/20170124/cda66c477aa946eeba45408d4129b274_th.jpeg)

é€šè¿‡å‘æƒé‡å¼ é‡æ·»åŠ ä¸€ä¸ªç»´åº¦ï¼Œèƒ½å¤Ÿå°†ä¸¤ç»„æˆ–æ›´å¤šç»„çš„æƒé‡é‡å†™ä¸ºä¸€ç»„æƒé‡ï¼Œè¿™æ ·å°±ç»™å‡ºäº†ä¸€ä¸ªå·ç§¯å±‚çš„æƒé‡å¼ é‡çš„é€šç”¨å®ç°ã€‚ç”±äºè¾“å…¥ã€è¾“å‡ºé€šé“çš„æ•°é‡éƒ½æ˜¯å‚æ•°ï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹å †å å¼ï¼ˆstackingï¼‰å’Œé“¾å¼ï¼ˆchainingï¼‰çš„å·ç§¯å±‚ã€‚

ã€€ã€€![img](http://img.mp.itc.cn/upload/20170124/10228a2a4d134aa0aa3077cb019d34a9_th.jpeg)

æœ€åï¼Œæˆ‘ä»¬éœ€è¦æå–ä¿¡æ¯ã€‚åœ¨æœ€åä¸€å±‚ä¸­ï¼Œæˆ‘ä»¬ä»…ä»…æƒ³ä½¿ç”¨ 10 ä¸ªç¥ç»å…ƒæ¥åˆ†ç±» 0-9 åä¸ªä¸åŒçš„æ•°å­—ã€‚ä¼ ç»Ÿä¸Šï¼Œè¿™æ˜¯é€šè¿‡ã€Œæœ€å¤§æ± åŒ–ï¼ˆmax-poolingï¼‰ã€å±‚æ¥å®Œæˆçš„ã€‚å³ä½¿ä»Šå¤©æœ‰è®¸å¤šæ›´ç®€å•çš„æ–¹æ³•èƒ½å¤Ÿå®ç°è¿™åˆ†ç±»ä»»åŠ¡ï¼Œä½†æ˜¯ï¼Œã€Œæœ€å¤§æ± åŒ–ã€èƒ½å¤Ÿå¸®åŠ©æˆ‘ä»¬ç›´è§‰åœ°ç†è§£å·ç§¯ç¥ç»ç½‘ç»œæ˜¯æ€ä¹ˆå·¥ä½œçš„ã€‚å¦‚æœä½ è®¤ä¸ºåœ¨è®­ç»ƒçš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬çš„å°å—æƒé‡ä¼šå‘å±•æˆèƒ½å¤Ÿè¿‡æ»¤åŸºæœ¬å½¢çŠ¶ï¼ˆæ°´å¹³çº¿ã€å‚ç›´çº¿æˆ–æ›²çº¿ç­‰ï¼‰çš„è¿‡æ»¤å™¨ï¼ˆfilterï¼‰ï¼Œé‚£ä¹ˆï¼Œæå–æœ‰ç”¨ä¿¡æ¯çš„æ–¹å¼å°±æ˜¯è¯†åˆ«è¾“å‡ºå±‚ä¸­å“ªç§å½¢çŠ¶å…·æœ‰æœ€å¤§çš„å¼ºåº¦ã€‚å®é™…ä¸Šï¼Œåœ¨æœ€å¤§æ± åŒ–å±‚ä¸­ï¼Œç¥ç»å…ƒçš„è¾“å‡ºæ˜¯åœ¨ 2x2 çš„åˆ†ç»„ä¸­è¢«å¤„ç†ï¼Œæœ€åä»…ä»…ä¿ç•™è¾“å‡ºæœ€å¤§å¼ºåº¦çš„ç¥ç»å…ƒã€‚

è¿™é‡Œæœ‰ä¸€ç§æ›´ç®€å•çš„æ–¹æ³•ï¼šå¦‚æœä½ æ˜¯ä»¥ä¸€æ­¥ä¸¤ä¸ªåƒç´ ç§»åŠ¨å›¾ç‰‡ä¸Šçš„æ»‘å—è€Œä¸æ˜¯ä»¥æ¯æ­¥ä¸€ä¸ªåƒç´ åœ°ç§»åŠ¨å›¾ç‰‡ä¸Šçš„æ»‘å—ã€‚è¿™ç§æ–¹æ³•å°±æ˜¯æœ‰æ•ˆçš„ï¼Œä»Šå¤©çš„å·ç§¯ç½‘ç»œä»…ä»…ä½¿ç”¨äº†å·ç§¯å±‚ã€‚

è®©æˆ‘ä»¬å»ºç«‹ä¸€ä¸ªç”¨äºæ‰‹å†™æ•°å­—è¯†åˆ«çš„å·ç§¯ç½‘ç»œã€‚åœ¨é¡¶éƒ¨ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ 3 ä¸ªå·ç§¯å±‚ï¼›åœ¨åº•éƒ¨ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¼ ç»Ÿçš„ softmax è¯»å‡ºå±‚ï¼Œå¹¶å°†å®ƒä»¬ç”¨å®Œå…¨è¿æ¥å±‚è¿æ¥ã€‚

ã€€ã€€![img](http://img.mp.itc.cn/upload/20170124/d3ae69380cae4dddbfc0f3523a264f4e_th.jpeg)

æ³¨æ„ï¼Œç¬¬äºŒä¸ç¬¬ä¸‰å·ç§¯å±‚ç¥ç»å…ƒæ•°é‡ä»¥ 2x2 ä¸ºå€æ•°å‡å°‘ï¼Œè¿™å°±è§£é‡Šäº†ä¸ºä»€ä¹ˆå®ƒä»¬çš„è¾“å‡ºå€¼ä» 28x28 å‡å°‘ä¸º 14x14ï¼Œç„¶åå†åˆ° 7x7ã€‚å·ç§¯å±‚çš„å¤§å°å˜åŒ–ä½¿ç¥ç»å…ƒçš„æ•°é‡åœ¨æ¯å±‚ä¸‹é™çº¦ä¸ºï¼š28x28x14â‰ˆ3000->14x14x8â‰ˆ1500 â†’ 7x7x12â‰ˆ500 â†’ 200ã€‚ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ç»™å‡ºè¯¥ç½‘ç»œçš„å…·ä½“å®ç°ã€‚

### å®ç°ï¼šä¸€ä¸ªå·ç§¯ç½‘ç»œ

![img](http://img.mp.itc.cn/upload/20170124/bf6ccfdee1bc440db5e14229a5799aa3_th.jpeg)

ä¸ºäº†å°†æˆ‘ä»¬çš„ä»£ç è½¬åŒ–ä¸ºå·ç§¯æ¨¡å‹ï¼Œæˆ‘ä»¬éœ€è¦ä¸ºå·ç§¯å±‚å®šä¹‰é€‚å½“çš„æƒé‡å¼ é‡ï¼Œç„¶åå°†è¯¥å·ç§¯å±‚æ·»åŠ åˆ°æ¨¡å‹ä¸­ã€‚æˆ‘ä»¬å·²ç»ç†è§£åˆ°å·ç§¯å±‚éœ€è¦ä»¥ä¸‹å½¢å¼çš„æƒé‡å¼ é‡ã€‚ä¸‹é¢ä»£ç æ˜¯ç”¨ TensorFlow è¯­æ³•æ¥å¯¹å…¶åˆå§‹åŒ–ï¼š

ã€€ã€€![img](http://img.mp.itc.cn/upload/20170124/dee5ee4d2bda42298813d9819ce61a24_th.jpeg)

ã€€ã€€W = tf.Variable(tf.truncated_normal([4, 4, 3, 2], stddev=0.1))

ã€€ã€€B = tf.Variable(tf.ones([2])/10) # 2 is the number of output channels

åœ¨ TensorFlow ä¸­ï¼Œä½¿ç”¨ tf.nn.conv2d å‡½æ•°å®ç°å·ç§¯å±‚ï¼Œè¯¥å‡½æ•°ä½¿ç”¨æä¾›çš„æƒé‡åœ¨ä¸¤ä¸ªæ–¹å‘ä¸Šæ‰«æè¾“å…¥å›¾ç‰‡ã€‚è¿™ä»…ä»…æ˜¯ç¥ç»å…ƒçš„åŠ æƒå’Œéƒ¨åˆ†ï¼Œä½ éœ€è¦æ·»åŠ åç½®å•å…ƒå¹¶å°†åŠ æƒå’Œæä¾›ç»™æ¿€æ´»å‡½æ•°ã€‚

ã€€ã€€stride = 1 # output is still 28x28

ã€€ã€€Ycnv = tf.nn.conv2d(X, W, strides=[1, stride, stride, 1], padding='SAME')

ã€€ã€€Y = tf.nn.relu(Ycnv + B)

ä¸è¦è¿‡åˆ†åœ¨æ„ stride çš„å¤æ‚è¯­æ³•ï¼ŒæŸ¥é˜…æ–‡æ¡£å°±èƒ½è·å–å®Œæ•´çš„è¯¦ç»†ä¿¡æ¯ã€‚è¿™é‡Œçš„å¡«å……ï¼ˆpaddingï¼‰ç­–ç•¥æ˜¯ä¸ºäº†å¤åˆ¶å›¾ç‰‡çš„è¾¹ç¼˜çš„åƒç´ ã€‚æ‰€æœ‰çš„æ•°å­—éƒ½åœ¨ä¸€ä¸ªç»Ÿä¸€çš„èƒŒæ™¯ä¸‹ï¼Œæ‰€ä»¥è¿™ä»…ä»…æ˜¯æ‰©å±•äº†èƒŒæ™¯ï¼Œå¹¶ä¸”ä¸åº”è¯¥æ·»åŠ ä¸éœ€è¦çš„ä»»ä½•æ ·å¼ã€‚

ç°åœ¨è¯¥ä½ äº†ã€‚ä¿®æ”¹ä½ çš„æ¨¡å‹å¹¶å°†å…¶è½¬åŒ–ä¸ºå·ç§¯æ¨¡å‹ã€‚ä½ å¯ä»¥ä½¿ç”¨ä¸Šå›¾ä¸­çš„å€¼æ¥ä¿®æ”¹å®ƒï¼Œä½ å¯ä»¥å‡å°ä½ çš„å­¦ä¹ é€Ÿç‡ä½†æ˜¯åŠ¡å¿…å…ˆç§»é™¤ dropoutã€‚

ä½ çš„æ¨¡å‹çš„å‡†ç¡®ç‡åº”è¯¥ä¼šè¶…è¿‡ 98%ï¼Œå¹¶ä¸”æœ€ç»ˆè¾¾åˆ°çº¦ 99%ã€‚çœ¼çœ‹ç›®æ ‡å°±è¦å®ç°ï¼Œæˆ‘ä»¬ä¸èƒ½åœæ­¢ï¼çœ‹çœ‹æµ‹è¯•çš„äº¤å‰ç†µæ›²çº¿ã€‚åœ¨ä½ çš„å¤´è„‘ä¸­ï¼Œæ­¤æ—¶ï¼Œæ˜¯å¦è§£å†³æ–¹æ¡ˆæ­£åœ¨å½¢æˆï¼Ÿ

ã€€ã€€![img](http://img.mp.itc.cn/upload/20170124/cb5d786d95ac44a5a9bc42c90d212f69_th.jpeg)

### 99% å‡†ç¡®ç‡çš„æŒ‘æˆ˜

è°ƒæ•´ä½ çš„ç¥ç»ç½‘ç»œçš„ä¸€ä¸ªå¥½æ–¹æ³•ï¼šå…ˆå»å®ç°ä¸€ä¸ªé™åˆ¶è¾ƒå¤šçš„ç¥ç»ç½‘ç»œï¼Œç„¶åç»™å®ƒæ›´å¤šçš„è‡ªç”±åº¦å¹¶ä¸”å¢åŠ  dropoutï¼Œä½¿ç¥ç»ç½‘ç»œé¿å…è¿‡æ‹Ÿåˆã€‚æœ€ç»ˆä½ å°†å¾—åˆ°ä¸€ä¸ªç›¸å½“ä¸é”™çš„ç¥ç»ç½‘ç»œã€‚

ä¾‹å¦‚ï¼Œæˆ‘ä»¬åœ¨ç¬¬ä¸€å±‚å·ç§¯å±‚ä¸­ä»…ä»…ä½¿ç”¨äº† 4 ä¸ª patchï¼Œå¦‚æœè¿™äº›æƒé‡çš„ patch åœ¨è®­ç»ƒçš„è¿‡ç¨‹ä¸­å‘å±•æˆä¸åŒçš„è¯†åˆ«å™¨ï¼Œä½ å¯ä»¥ç›´è§‚åœ°çœ‹åˆ°è¿™å¯¹äºè§£å†³æˆ‘ä»¬çš„é—®é¢˜æ˜¯ä¸å¤Ÿçš„ã€‚æ‰‹å†™æ•°å­—æ¨¡å¼è¿œå¤šäº 4 ç§åŸºæœ¬æ ·å¼ã€‚

å› æ­¤ï¼Œè®©æˆ‘ä»¬ç¨å¾®å¢åŠ  patch çš„æ•°é‡ï¼Œå°†æˆ‘ä»¬å·ç§¯å±‚ä¸­ patch çš„æ•°é‡ä» 4ï¼Œ8ï¼Œ12 å¢åŠ åˆ° 6ï¼Œ12ï¼Œ24ï¼Œå¹¶ä¸”åœ¨å…¨è¿æ¥å±‚ä¸Šæ·»åŠ  dropoutã€‚å®ƒä»¬çš„ç¥ç»å…ƒé‡å¤ä½¿ç”¨ç›¸åŒçš„æƒé‡ï¼Œåœ¨ä¸€æ¬¡è®­ç»ƒè¿­ä»£ä¸­ï¼Œé€šè¿‡å†»ç»“ï¼ˆé™åˆ¶ï¼‰ä¸€äº›ä¸ä¼šå¯¹å®ƒä»¬èµ·ä½œç”¨çš„æƒé‡ï¼Œdropout èƒ½å¤Ÿæœ‰æ•ˆåœ°å·¥ä½œã€‚

![img](http://img.mp.itc.cn/upload/20170124/5792c4f41a734c44b4f1c3ee40e47742_th.jpeg)

åŠ æ²¹å§ï¼Œå»æ‰“ç ´ 99ï¼…çš„é™åˆ¶ã€‚å¢åŠ  patch æ•°é‡å’Œé€šé“çš„æ•°é‡ï¼Œå¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œåœ¨å·ç§¯å±‚ä¸­æ·»åŠ  dropoutã€‚

ã€€ã€€![img](http://img.mp.itc.cn/upload/20170124/e2e13da25b6146f2b0274a19187e18c0_th.jpeg)

è§£å†³æ–¹æ¡ˆå¯ä»¥åœ¨æ–‡ä»¶ mnist_3.1_convolutional_bigger_dropout.py ä¸­æ‰¾åˆ°ã€‚

ä½¿ç”¨ä¸Šå›¾æ‰€ç¤ºçš„æ¨¡å‹ï¼Œåœ¨ 10000 ä¸ªæµ‹è¯•çš„æ•°å­—ä¸­ï¼Œç»“æœä»…ä»…é”™è¯¯äº† 72 ä¸ªã€‚ä½ å¯ä»¥åœ¨ MNIST ç½‘ç«™ä¸Šå‘ç°ï¼Œæ•°å­—è¯†åˆ«å‡†ç¡®ç‡çš„ä¸–ç•Œçºªå½•å¤§çº¦ä¸º 99.7%ï¼Œè¿™ä»…æ¯”æˆ‘ä»¬ç”¨ 100 è¡Œ Python/TensorFlow ä»£ç æ„å»ºçš„æ¨¡å‹çš„å‡†ç¡®ç‡é«˜ 0.4%ã€‚

æœ€åï¼Œä¸åŒçš„ dropout ä½¿æˆ‘ä»¬èƒ½å¤Ÿè®­ç»ƒæ›´å¤§çš„å·ç§¯ç½‘ç»œã€‚å¢åŠ ç¥ç»ç½‘ç»œçš„é¢å¤–è‡ªç”±åº¦ï¼Œä½¿æ¨¡å‹çš„æœ€ç»ˆå‡†ç¡®ç‡ä» 98.9% è¾¾åˆ° 99.1%ã€‚å‘å·ç§¯å±‚ä¸­å¢åŠ  dropout ä¸ä»…å‡å°‘äº†æµ‹è¯•è¯¯å·®ï¼Œè€Œä¸”ä½¿æˆ‘ä»¬æ¨¡å‹çš„å‡†ç¡®ç‡çªç ´ 99%ï¼Œç”šè‡³è¾¾åˆ°äº† 99.3%ã€‚

![img](http://img.mp.itc.cn/upload/20170124/70c0a9eed13d48e793d06de2317a006f_th.jpeg)

### æ­å–œ

ä½ å·²ç»å»ºç«‹äº†ä½ çš„ç¬¬ä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œå¹¶ä¸”è®­ç»ƒç²¾åº¦è¾¾åˆ°äº† 99%ã€‚åœ¨è¿™ä¸ªå­¦ä¹ è¿‡ç¨‹ä¸­ï¼Œä½ æ‰€å­¦åˆ°çš„æŠ€æœ¯ï¼Œå¹¶ä¸å±€é™äº MNIST æ•°æ®é›†ã€‚å®é™…ä¸Šï¼Œè¿™äº›æŠ€æœ¯åœ¨è®­ç»ƒç¥ç»ç½‘ç»œçš„è¿‡ç¨‹ä¸­è¢«å¹¿æ³›ä½¿ç”¨ã€‚ä½œä¸ºç¤¼ç‰©ï¼Œä¸‹é¢æä¾›çš„å†…å®¹å¯ä»¥ç”¨æ¥å¸®åŠ©ä½ å›å¿†å·²ç»æ‰€å­¦çš„å†…å®¹ã€‚

- åœ¨å®Œæˆäº†å®Œå…¨ç¥ç»ç½‘ç»œå’Œå·ç§¯ç½‘ç»œåï¼Œä½ åº”è¯¥å­¦ä¹ å¾ªç¯ç¥ç»ç½‘ç»œï¼šhttps://www.tensorflow.org/tutorials/recurrent/ã€‚
- åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œä½ å·²ç»å­¦ä¹ äº†å¦‚ä½•åœ¨çŸ©é˜µå±‚æ¬¡æ„å»º TensorFlow æ¨¡å‹ã€‚Tensorflow è¿˜æœ‰æ›´é«˜çº§çš„ APIï¼Œç§°ä¸º tf.learnï¼šhttps://www.tensorflow.org/tutorials/tflearn/
- è¦åœ¨äº‘ä¸Šçš„åˆ†å¸ƒå¼æ¡†æ¶ä¸Šè®­ç»ƒï¼Œæˆ‘ä»¬æä¾› Cloud ML æœåŠ¡ï¼šhttps://cloud.google.com/ml
- æœ€åï¼Œæˆ‘ä»¬å¸Œæœ›æ”¶åˆ°ä½ çš„åé¦ˆã€‚å¦‚æœä½ åœ¨å‘ç°äº†æœ¬å®éªŒä¸­çš„äº›è®¸é”™è¯¯ï¼Œæˆ–è€…ä½ è®¤ä¸ºæœ‰ä»€ä¹ˆéœ€è¦æ”¹è¿›çš„åœ°æ–¹ï¼Œè¯·å‘Šè¯‰æˆ‘ä»¬ã€‚æˆ‘ä»¬é€šè¿‡ GitHub å¤„ç†åé¦ˆï¼Œ[åé¦ˆé“¾æ¥](https://github.com/googlecodelabs/feedback/issues/new?title=[cloud-tensorflow-mnist]:&labels[]=content-platform&labels[]=cloud)ã€‚

## åè®°

è™½ç„¶çœ‹ä¸æ‡‚ï¼Œä½†æ˜¯å…ˆæ··ä¸ªè„¸ç†Ÿï¼Œä»¥åæ…¢æ…¢å†çœ‹ã€‚æœ¬æ–‡å¤§éƒ¨åˆ†å†…å®¹å¤åˆ¶è‡ª[æ•™ç¨‹ | æ²¡æœ‰åšå£«å­¦ä½ï¼Œç…§æ ·ç©è½¬TensorFlowæ·±åº¦å­¦ä¹ ](http://it.sohu.com/20170124/n479480999.shtml)ã€‚